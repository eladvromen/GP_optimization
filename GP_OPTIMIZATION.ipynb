{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERT_PATH = '..\\\\research\\data_expert_demo.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_data = pd.read_hdf(EXPERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_note_range_column(songs_dict, expert_data):\n",
    "    note_ranges = [songs_dict.get(filename) for filename in expert_data['midi_filename']]\n",
    "    expert_data['note_range'] = note_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#for adding note range\n",
    "# Load dictionary from JSON file\n",
    "with open('song_dict.json', 'r') as f:\n",
    "    song_dict = json.load(f)\n",
    "add_note_range_column(song_dict, expert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>username</th>\n",
       "      <th>practice_mode</th>\n",
       "      <th>bpm</th>\n",
       "      <th>error_before_left_timing</th>\n",
       "      <th>error_before_right_timing</th>\n",
       "      <th>error_before_left_pitch</th>\n",
       "      <th>error_before_right_pitch</th>\n",
       "      <th>error_after_left_timing</th>\n",
       "      <th>error_after_right_timing</th>\n",
       "      <th>error_after_left_pitch</th>\n",
       "      <th>error_after_right_pitch</th>\n",
       "      <th>note_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>song1.mid</td>\n",
       "      <td>elad_demo_0</td>\n",
       "      <td>IMP_TIMING</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_TIMING</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     midi_filename      username practice_mode   bpm  \\\n",
       "0        song1.mid   elad_demo_0    IMP_TIMING  75.0   \n",
       "1  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "2  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "3  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "4  83b_HaAviv.midi  elad_demo_01    IMP_TIMING  85.0   \n",
       "\n",
       "   error_before_left_timing  error_before_right_timing  \\\n",
       "0                       0.0                   0.036429   \n",
       "1                       0.0                   0.078066   \n",
       "2                       0.0                   0.049352   \n",
       "3                       0.0                   0.040376   \n",
       "4                       0.0                   0.021390   \n",
       "\n",
       "   error_before_left_pitch  error_before_right_pitch  error_after_left_timing  \\\n",
       "0                      0.0                  0.000000                      0.0   \n",
       "1                      0.0                  0.152778                      0.0   \n",
       "2                      0.0                  0.250000                      0.0   \n",
       "3                      0.0                  0.013889                      0.0   \n",
       "4                      0.0                  0.000000                      0.0   \n",
       "\n",
       "   error_after_right_timing  error_after_left_pitch  error_after_right_pitch  \\\n",
       "0                  0.030571                     0.0                 0.000000   \n",
       "1                  0.049352                     0.0                 0.250000   \n",
       "2                  0.040376                     0.0                 0.013889   \n",
       "3                  0.021390                     0.0                 0.000000   \n",
       "4                  0.017971                     0.0                 0.000000   \n",
       "\n",
       "   note_range  \n",
       "0           5  \n",
       "1          11  \n",
       "2          11  \n",
       "3          11  \n",
       "4          11  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "Error = namedtuple(\"Error\", \"pitch timing\")\n",
    "\n",
    "BPM_BOUNDS = [50,200]\n",
    "\n",
    "#### SIMPLIFIED ENUMS\n",
    "import enum\n",
    "class PracticeMode(enum.Enum):\n",
    "    IMP_PITCH = enum.auto()\n",
    "    IMP_TIMING = enum.auto()\n",
    "    \n",
    "class NoteRangePerHand(enum.Enum):\n",
    "    EASY = 0.5\n",
    "    MEDIUM = 1.5\n",
    "    HARD = 3.0\n",
    "    \n",
    "\n",
    "import dataclasses as dc\n",
    "from dataclasses import dataclass, astuple    \n",
    "@dataclass\n",
    "class TaskParameters:\n",
    "    \"\"\"\n",
    "    We need to redefine this to use the new, simplified NoteRangePerHand.\n",
    "    \n",
    "    \n",
    "    TODO: Should we include the parameters we are not using here?\n",
    "        maybe just clarify which one we are using in this simplified case\n",
    "    \"\"\"\n",
    "    \n",
    "    ## USED IN SIMPLIFIED CASE\n",
    "    bpm: float              = 120\n",
    "    note_range: NoteRangePerHand = NoteRangePerHand.MEDIUM\n",
    "    \n",
    "    ## UNUSED HERE, but used in real application\n",
    "    timeSignature: tuple    = (4,4)\n",
    "    noteValues: list        = dc.field(default_factory= lambda: [1, 1 / 2, 1 / 4, 1 / 8] )\n",
    "    maxNotesPerBar: int       = 3\n",
    "    noOfBars: int           = 7\n",
    "    note_range: NoteRangePerHand = NoteRangePerHand.MEDIUM\n",
    "    left: bool              = False\n",
    "    right: bool             = True\n",
    "    \n",
    "    \n",
    "    def astuple(self):\n",
    "        return astuple(self)\n",
    "    \n",
    "\n",
    "## Mappings of categorical data to ints.\n",
    "### The pracice modes will be mapped onto a single dimension, placed far away\n",
    "### from each other\n",
    "practicemode2int = {pm: i*1000 for i, pm in enumerate(PracticeMode)}\n",
    "int2practicemode = {i*1000: pm for i, pm in enumerate(PracticeMode)}\n",
    "    \n",
    "### The note range will be one-hot encoded, but we still need dicts to convert\n",
    "noterange2int = {pm: i for i, pm in enumerate(NoteRangePerHand)}\n",
    "int2noterange = {i: pm for i, pm in enumerate(NoteRangePerHand)}\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import GPyOpt\n",
    "import GPy\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPPlotData:\n",
    "    X1: np.array = None\n",
    "    X2: np.array = None\n",
    "    mean: np.array = None \n",
    "    mean_max: float = None\n",
    "    mean_min: float = None\n",
    "    std: np.array = None\n",
    "    std_max: float = None\n",
    "    std_min: float = None\n",
    "    acq: np.array = None\n",
    "    acq_max: float = None\n",
    "    acq_min: float = None\n",
    "    \n",
    "    def apply_to_arrays(self, func):\n",
    "        return [\n",
    "            func(self.mean),\n",
    "            func(self.std),\n",
    "            func(self.acq),\n",
    "            ]\n",
    "\n",
    "\n",
    "class GaussianProcess:\n",
    "    def __init__(self, bpm_norm_fac=100):\n",
    "        self.data_X = None#should be the task parameters\n",
    "        self.data_X_old_shape = None\n",
    "        \n",
    "        self.data_Y = None#should be the error after\n",
    "        \n",
    "        self.bpm_norm_fac = bpm_norm_fac\n",
    "        \n",
    "        self.domain =[\n",
    "            {'name': 'complexity_level', 'type': 'discrete', 'domain': tuple(range(10))},\n",
    "            {'name': 'practice_mode', 'type': 'discrete', 'domain': tuple(i*1000 for i , _ in enumerate(PracticeMode))},\n",
    "            {'name': 'note_range', 'type': 'categorical', 'domain': (0,1,2)},\n",
    "            {'name': 'bpm', 'type': 'continuous', 'domain': \n",
    "                 (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))},\n",
    "                 \n",
    "                ]\n",
    "                 \n",
    "        self.space = GPyOpt.core.task.space.Design_space(self.domain)\n",
    "        \n",
    "    def _norm_bpm(self, v):\n",
    "        return v/self.bpm_norm_fac\n",
    "        \n",
    "    def _params2domain(self, complexity_level, task_parameters, practice_mode):\n",
    "        domain_x = [complexity_level,\n",
    "                    practicemode2int[practice_mode],\n",
    "                    noterange2int[task_parameters.note_range],\n",
    "                    self._norm_bpm(task_parameters.bpm),\n",
    "                    ]\n",
    "        \n",
    "        \n",
    "        return np.array([domain_x])\n",
    "        \n",
    "    def _domain2space(self, domain_x):\n",
    "        ## Converts the domain variables into the GPs input space\n",
    "        ## does one-hot encoding\n",
    "        space_rep = self.space.unzip_inputs(domain_x)\n",
    "        return space_rep\n",
    "    \n",
    "        \n",
    "    def _get_bayes_opt(self):\n",
    "        return self.bayes_opt\n",
    "        \n",
    "    \n",
    "    def update_model(self):\n",
    "\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        # kernel = GPy.kern.RBF(input_dim=self.space.model_dimensionality, \n",
    "        #                       variance=0.01, \n",
    "        #                       lengthscale=1)\n",
    "\n",
    "\n",
    "        #here to add modularity- different kernels for different  hyperparameters\n",
    "        \n",
    "        kernel = GPy.kern.Matern52(input_dim=self.space.model_dimensionality, \n",
    "                              variance=0.01, \n",
    "                              lengthscale=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt._update_model() \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt._update_model() \n",
    "        \n",
    "#experimental\n",
    "\n",
    "    def update_model_with_kernel(self, kernel):\n",
    "    #it seems possible to enter the kernel to the functionality...\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        \n",
    "        \n",
    "    #sort of predict that gives utility\n",
    "    def get_estimate(self, complexity_level, task_parameters, practice_mode,\n",
    "                     add_variance=True):\n",
    "        if not hasattr(self, \"bayes_opt\"):\n",
    "            # if there is no model yet, e.g. in the first iteration\n",
    "            # print(\"(GP) DATA_X IS NONE, RETURNING RANDOM NUMBER\")\n",
    "            return random.random()\n",
    "        \n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        X = self._params2domain(complexity_level, task_parameters, practice_mode)\n",
    "        X = self._domain2space(X)\n",
    "        \n",
    "        mean, var = bayes_opt.model.predict(X)\n",
    "        \n",
    "        r = mean[0]\n",
    "        if add_variance:\n",
    "            r += np.sqrt(var[0])\n",
    "        return r\n",
    "        \n",
    "    #choose the best practice mode from utility estimate\n",
    "    def get_best_practice_mode(self, complexity_level, task_parameters):\n",
    "        all_practice_modes = list(PracticeMode)\n",
    "        if random.random() > 0.05:\n",
    "            max_i = np.argmax([self.get_estimate(complexity_level, task_parameters, pm)\n",
    "                                             for pm in all_practice_modes])\n",
    "            return all_practice_modes[max_i]\n",
    "        \n",
    "        else:\n",
    "            # use weighted choice based on softmax\n",
    "            # increases exploration\n",
    "            def softmax(x):\n",
    "                return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            \n",
    "            return random.choices(all_practice_modes, \n",
    "                                  softmax(\n",
    "                [0.5*self.get_estimate(complexity_level, task_parameters, pm)\n",
    "                                             for pm in all_practice_modes]), k=1)[0]\n",
    "            \n",
    "    \n",
    "    def add_data_point(self, complexity_level, task_parameters, practice_mode, \n",
    "                       utility_measurement):\n",
    "        new_x =  self._params2domain(complexity_level, task_parameters, practice_mode) \n",
    "        new_y = [ utility_measurement ]\n",
    "        \n",
    "        if self.data_X is None:\n",
    "            self.data_X = new_x\n",
    "            self.data_Y = [new_y]\n",
    "        else:\n",
    "            self.data_X = np.vstack((self.data_X, new_x[0]))\n",
    "            self.data_Y = np.vstack((self.data_Y, new_y[0]))\n",
    "    \n",
    "    def get_policy(self, c):\n",
    "        if not hasattr(self, \"bayes_opt\"):\n",
    "            return np.round(np.random.random((3*150,1)))\n",
    "        \n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        data_dict = defaultdict(GPPlotData)\n",
    "        for i, practice_mode in enumerate([PracticeMode.IMP_TIMING,\n",
    "                                           PracticeMode.IMP_PITCH]):\n",
    "            # insert plot data into the data_dict\n",
    "            self._get_plot_data(data_dict, c, practice_mode, bayes_opt)\n",
    "            \n",
    "        return np.argmax([d.mean for d in [\n",
    "            data_dict[PracticeMode.IMP_TIMING], data_dict[PracticeMode.IMP_PITCH]]], axis=0)\n",
    "    \n",
    "    \n",
    "    def _get_plot_data(self, data_dict, c, practice_mode, bayes_opt, for_plot=False):\n",
    "        bounds = [[0,3], (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))]\n",
    "        \n",
    "        acquisition_function = bayes_opt.acquisition.acquisition_function\n",
    "        model = bayes_opt.model\n",
    "        \n",
    "        if not for_plot:\n",
    "            X1 = np.array([0,1,2])\n",
    "            X1_axis = X1\n",
    "            reshape_dim = 3*150\n",
    "        else:\n",
    "            X1_axis = np.linspace(bounds[0][0], bounds[0][1], 150, endpoint=False)\n",
    "            X1 = np.array([0]*50 + [1]*50 + [2]*50)\n",
    "            reshape_dim = 150*150\n",
    "            \n",
    "        X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "        \n",
    "        x1, x2 = np.meshgrid(X1, X2)\n",
    "        X = np.hstack((\n",
    "            \n",
    "            np.array([c]*(reshape_dim)).reshape(reshape_dim,1),\n",
    "            np.array([practicemode2int[practice_mode]]*(reshape_dim)).reshape(reshape_dim,1),\n",
    "            x1.reshape(reshape_dim,1),\n",
    "             x2.reshape(reshape_dim,1)))\n",
    "        \n",
    "        X_spaced = self._domain2space(X)\n",
    "         \n",
    "        acqu = acquisition_function(X_spaced)\n",
    "        \n",
    "        m, v = model.predict(X_spaced)\n",
    "        \n",
    "        if type(m) == list:\n",
    "            m = m[0]\n",
    "        \n",
    "        if type(v) == list:\n",
    "            v = v[0]\n",
    "        \n",
    "        if type(acqu) == list:\n",
    "            acqu = acqu[0]\n",
    "        \n",
    "        data_dict[practice_mode].mean = m\n",
    "        data_dict[practice_mode].std = np.sqrt(v)\n",
    "        data_dict[practice_mode].acq = acqu\n",
    "        data_dict[practice_mode].X1 = X1_axis\n",
    "        data_dict[practice_mode].X2 = X2\n",
    "        \n",
    "    \n",
    "    def _plot_single_practice_mode(self, gp_plot_data, subplotf,\n",
    "                                   plot_mean=True,\n",
    "                                   plot_std=True,\n",
    "                                   plot_acq=True):\n",
    "        label_x = \"NoteRange\"\n",
    "        label_y = \"BPM\"\n",
    "        \n",
    "        X_TICKS = ([0.5,1.5,2.5], [\"0\", \"1\", \"2\"])\n",
    "        \n",
    "        bounds = [[0,3], (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))]\n",
    "        \n",
    "        ## Derived from GPyOpt/plotting/plots_bo.py\n",
    "        X1 = gp_plot_data.X1\n",
    "        X2 = gp_plot_data.X2\n",
    "        \n",
    "        def inflate_array(a):\n",
    "            return a.reshape((150,150))\n",
    "        \n",
    "        subplot_count = 0\n",
    "        \n",
    "        if plot_mean:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.mean),100,\n",
    "                         vmin=gp_plot_data.mean_min,\n",
    "                         vmax=gp_plot_data.mean_max,)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Posterior mean')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "        ##\n",
    "        \n",
    "        if plot_std:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.std),100,\n",
    "                         vmin=gp_plot_data.std_min,\n",
    "                         vmax=gp_plot_data.std_max)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Posterior sd.')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "        ##\n",
    "        \n",
    "        \n",
    "        if plot_acq:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.acq),100,\n",
    "                         vmin=gp_plot_data.acq_min,\n",
    "                         vmax=gp_plot_data.acq_max,)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Acquisition function')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "            \n",
    "    \n",
    "    def plot_mutiple(self, c, practice_modes,\n",
    "                                   plot_mean=True,\n",
    "                                   plot_std=True,\n",
    "                                   plot_acq=False):\n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        n_rows = len(practice_modes)\n",
    "        n_cols = sum([plot_mean, plot_std, plot_acq])\n",
    "        \n",
    "        data_dict = defaultdict(GPPlotData)\n",
    "        for i, practice_mode in enumerate(practice_modes):\n",
    "            self._get_plot_data(data_dict, c, practice_mode, bayes_opt,\n",
    "                                for_plot=True)\n",
    "            \n",
    "        mean_max, std_max, acq_max = np.max([d.apply_to_arrays(np.max) for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        mean_min, std_min, acq_min = np.min([d.apply_to_arrays(np.min) for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        for pd in data_dict.values():\n",
    "            pd.mean_max = mean_max\n",
    "            pd.mean_min = mean_min\n",
    "            pd.std_max = std_max\n",
    "            pd.std_min = std_min\n",
    "            pd.acq_max = acq_max\n",
    "            pd.acq_min = acq_min\n",
    "        \n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(n_cols*3.34,5*n_rows))\n",
    "        \n",
    "        for i, practice_mode in enumerate(practice_modes):\n",
    "            subplotf = lambda idx: plt.subplot(n_rows,n_cols,i*n_cols+idx)\n",
    "            self._plot_single_practice_mode(data_dict[practice_mode], subplotf,\n",
    "                                            plot_mean=plot_mean,\n",
    "                                            plot_std=plot_std,\n",
    "                                            plot_acq=plot_acq)\n",
    "            \n",
    "            ax = subplotf(1)\n",
    "            row = practice_mode.name\n",
    "            pad = 5\n",
    "            ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                        xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                        size='large', ha='right', va='center')\n",
    "        \n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.savefig(\"detailed_noise05.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        some_pd = list(data_dict.values())[0]\n",
    "        \n",
    "        argmax_plot_data = GPPlotData(X1=some_pd.X1, X2=some_pd.X2)\n",
    "        argmax_plot_data.mean = np.argmax([d.mean for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        argmax_plot_data.std = np.argmax([d.std for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        argmax_plot_data.acq = np.argmax([d.acq for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        subplotf = lambda idx: plt.subplot(1,3,idx)\n",
    "        \n",
    "        self._plot_single_practice_mode(argmax_plot_data, subplotf)\n",
    "        ax = subplotf(1)\n",
    "        row = \"ARGMAX\"\n",
    "        pad = 5\n",
    "        ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                    xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                    size='large', ha='right', va='center')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def gen_tasks(num_tasks=None, seed=546354):\n",
    "    assert num_tasks != None\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    for i in range(num_tasks):\n",
    "        bpm = rng.integers(*BPM_BOUNDS) \n",
    "        note_range = rng.choice(NoteRangePerHand)\n",
    "    \n",
    "        yield TaskParameters(bpm=bpm, note_range=note_range)\n",
    "    \n",
    "def task2error(task_parameters):\n",
    "    return Error(pitch=task_parameters.note_range.value,\n",
    "                timing=task_parameters.bpm/100\n",
    "                 )\n",
    "\n",
    "def task2error2(np_array):\n",
    "    def note_range_map(v):\n",
    "        import math\n",
    "        return [NoteRangePerHand.EASY.value, NoteRangePerHand.MEDIUM.value, \n",
    "                NoteRangePerHand.HARD.value][int(math.floor(v))]\n",
    "    \n",
    "    out = [[note_range_map(nr), bpm/100] for nr, bpm in np_array]\n",
    "    return np.array(out)\n",
    "\n",
    "    \n",
    "def per_after_practice(practice_mode, error):\n",
    "    if practice_mode == PracticeMode.IMP_PITCH:\n",
    "        return perf_after_pitch_practice(error)\n",
    "    if practice_mode == PracticeMode.IMP_TIMING:\n",
    "        return perf_after_timing_practice(error)\n",
    "    raise Exception()\n",
    "\n",
    "def perf_after_pitch_practice(error):\n",
    "    return Error(timing=error.timing,\n",
    "                 pitch=error.pitch*0.5)\n",
    "\n",
    "def perf_after_timing_practice(error):\n",
    "    return Error(timing=error.timing*0.5,\n",
    "                 pitch=error.pitch)\n",
    "\n",
    "def error_diff_to_utility(error_pre, error_post):\n",
    "    diff_timing = error_post.timing - error_pre.timing\n",
    "    diff_pitch  = error_post.pitch  - error_pre.pitch\n",
    "    \n",
    "    \n",
    "    MEAN_UTILITY = 0.75\n",
    "    \n",
    "    return - (diff_timing*1 + diff_pitch*1) - MEAN_UTILITY\n",
    "\n",
    "\n",
    "def calc_optimal_policy(performance):\n",
    "    bounds = [[0,3], BPM_BOUNDS]\n",
    "            \n",
    "    X1 = np.array([0,1,2])\n",
    "    X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "    x1, x2 = np.meshgrid(X1, X2)\n",
    "    X = np.hstack((    \n",
    "         x1.reshape(3*150,1),\n",
    "          x2.reshape(3*150,1)))\n",
    "    \n",
    "    error2d = task2error2(X)\n",
    "    error2d = np.array([performance(Error(*err)) for err in error2d])\n",
    "    \n",
    "    err_post_pitch = np.array(\n",
    "        [perf_after_pitch_practice(Error(*err)) for err in error2d])\n",
    "    \n",
    "    err_post_timing = np.array(\n",
    "        [perf_after_timing_practice(Error(*err)) for err in error2d])\n",
    "    \n",
    "    \n",
    "    argmax = np.argmin(np.vstack((\n",
    "        np.sum(err_post_timing, axis=1),\n",
    "        np.sum(err_post_pitch, axis=1)\n",
    "        )), axis=0)\n",
    "    \n",
    "    \n",
    "    error_diff = np.array([timing-pitch for timing, pitch in\n",
    "                          zip(\n",
    "        np.sum(err_post_timing, axis=1),\n",
    "        np.sum(err_post_pitch, axis=1))])\n",
    "    \n",
    "    return argmax.reshape(3*150,1), np.abs(error_diff.reshape(3*150,1))\n",
    "\n",
    "def compare_to_best_policy(policy_argmax, best_argmax, best_error_diff):\n",
    "    num_diff_cases = np.sum(np.abs(policy_argmax-best_argmax))\n",
    "    \n",
    "    abs_diff = num_diff_cases / policy_argmax.shape[0]\n",
    "    weighted_diff = np.sum(best_error_diff[policy_argmax!=best_argmax]) / \\\n",
    "                            (np.median(best_error_diff) * best_error_diff.shape[0])\n",
    "    \n",
    "    return abs_diff, weighted_diff\n",
    "\n",
    "def plot_best_policy():\n",
    "    label_x = \"NoteRange\"\n",
    "    label_y = \"BPM\"\n",
    "    \n",
    "    bounds = [[0,3], BPM_BOUNDS]\n",
    "    X_TICKS = ([0.5,1.5,2.5], [\"0\", \"1\", \"2\"])\n",
    "    \n",
    "    X1 = np.linspace(bounds[0][0], bounds[0][1], 150, endpoint=False)\n",
    "    X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "    x1, x2 = np.meshgrid(X1, X2)\n",
    "    X = np.hstack((    \n",
    "         x1.reshape(150*150,1),\n",
    "          x2.reshape(150*150,1)))\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    for idx, performance in enumerate([perf_bad_pitch, perf_balanced,\n",
    "                                       perf_bad_timing]):\n",
    "        title = [\"Bad Pitch\", \"Balanced\", \"Bad Timing\"][idx]\n",
    "        \n",
    "        error2d = task2error2(X)\n",
    "        error2d = np.array([performance(Error(*err)) for err in error2d])\n",
    "        \n",
    "        err_post_pitch = np.array(\n",
    "            [perf_after_pitch_practice(Error(*err)) for err in error2d])\n",
    "        \n",
    "        err_post_timing = np.array(\n",
    "            [perf_after_timing_practice(Error(*err)) for err in error2d])\n",
    "        \n",
    "        \n",
    "        argmax = np.argmin(np.vstack((\n",
    "            np.sum(err_post_timing, axis=1),\n",
    "            np.sum(err_post_pitch, axis=1)\n",
    "            )), axis=0)\n",
    "        \n",
    "        \n",
    "        plt.subplot(1, 3, idx+1)\n",
    "        plt.contourf(X1, X2, argmax.reshape(150,150),50,)\n",
    "        plt.xlabel(label_x)\n",
    "        if idx == 0:\n",
    "            plt.ylabel(label_y)\n",
    "        plt.title(title)\n",
    "        plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "        plt.xticks(*X_TICKS)\n",
    "        \n",
    "        if idx == 0:\n",
    "            from matplotlib.patches import Patch\n",
    "            cmap = plt.cm.viridis\n",
    "            custom_lines = [Patch(facecolor=cmap(1.)),\n",
    "                        Patch(facecolor=cmap(0.)),]\n",
    "            plt.legend(custom_lines, [\"IMP_PITCH\", \"IMP_TIMING\"])\n",
    "        \n",
    "    # plt.savefig(\"optimal_policies.eps\")\n",
    "    plt.show()\n",
    "    \n",
    "def single_experiment_run_tup(inp_tup, num_rounds):\n",
    "        performer, noise_var, bpm_norm_fac = inp_tup\n",
    "        gp, policy_diffs, kernel_params = single_experiment_run(\n",
    "                                    num_rounds=num_rounds, \n",
    "                                    performer=performer, \n",
    "                                    task_err_noise_var=noise_var, \n",
    "                                    utility_noise_var=noise_var, \n",
    "                                    bpm_norm_fac=bpm_norm_fac)\n",
    "        return (performer, noise_var, bpm_norm_fac), policy_diffs\n",
    "\n",
    "def single_experiment_run(num_rounds, \n",
    "                          performer, \n",
    "                          task_err_noise_var, utility_noise_var,\n",
    "                          bpm_norm_fac,\n",
    "                          seed=None,\n",
    "                          plot=False,\n",
    "                          print_details=False):\n",
    "    \n",
    "    if print_details:\n",
    "        from tqdm import tqdm\n",
    "    else:\n",
    "        def tqdm(iterable, **kwargs):\n",
    "            for x in iterable:\n",
    "                yield(x)\n",
    "    \n",
    "    seed = seed or random.randint(0, 2**16)\n",
    "    \n",
    "    performance_dict = dict(bad_pitch=perf_bad_pitch,\n",
    "                            balanced=perf_balanced,\n",
    "                            bad_timing=perf_bad_timing)\n",
    "    \n",
    "    perf_string = str(performer)\n",
    "    performer = performance_dict[perf_string]\n",
    "    \n",
    "    best_policy = calc_optimal_policy(performer)\n",
    "    policy_diffs = list()\n",
    "    kernel_params = list()\n",
    "    \n",
    "    GP = GaussianProcess(bpm_norm_fac=bpm_norm_fac)\n",
    "    c = 0\n",
    "    \n",
    "    for idx, tp in enumerate(tqdm(gen_tasks(num_rounds, seed=seed), \n",
    "                                  total=num_rounds)):\n",
    "        if idx % 3 == 0:\n",
    "            _pre = time.time()\n",
    "            \n",
    "            GP.update_model()\n",
    "            policy_diff = compare_to_best_policy(GP.get_policy(c),\n",
    "                *best_policy)\n",
    "            \n",
    "        \n",
    "        if hasattr(GP, \"bayes_opt\"):\n",
    "            kernel_params.append(list(map(lambda a:a.values[0],\n",
    "                    GP.bayes_opt.model.model.kern.parameters)))\n",
    "        \n",
    "        policy_diffs.append(policy_diff[1]) # only use weighted diff \n",
    "        \n",
    "        task_error = task2error(tp)\n",
    "        \n",
    "        task_error = Error(\n",
    "            pitch=task_error.pitch* random.gauss(1,task_err_noise_var),\n",
    "            timing=task_error.timing* random.gauss(1,task_err_noise_var),)\n",
    "        \n",
    "        \n",
    "        error_pre = performer(task_error)\n",
    "        given_practice_mode = GP.get_best_practice_mode(c, tp)\n",
    "        error_post = per_after_practice(given_practice_mode, error_pre)\n",
    "        utility = error_diff_to_utility(error_pre, error_post)\n",
    "        \n",
    "        utility *= random.gauss(1,utility_noise_var)\n",
    "        \n",
    "        GP.add_data_point(c, tp, given_practice_mode, utility)\n",
    "        \n",
    "        if print_details:\n",
    "            tqdm.write(\"\\n\")\n",
    "            tqdm.write(f\"NoteRange = {tp.note_range}\")\n",
    "            tqdm.write(f\"BPM = {tp.bpm}\")\n",
    "            tqdm.write(f\"Suggested PracticeMode: {given_practice_mode}\")\n",
    "            tqdm.write(f\"Error Pre: {error_pre}\")\n",
    "            tqdm.write(f\"Error post: {error_post}\")\n",
    "            tqdm.write(f\"Utility: {utility}\")\n",
    "            tqdm.write(f\"Policy Diff: {policy_diff}\")\n",
    "            tqdm.write(\"-\"*32)\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        GP.plot_mutiple(c, [\n",
    "            \n",
    "            PracticeMode.IMP_TIMING,\n",
    "            PracticeMode.IMP_PITCH,\n",
    "            ])\n",
    "        \n",
    "        plt.plot(list(range(len(policy_diffs))), policy_diffs)\n",
    "        plt.ylim((-0.01,None))\n",
    "        plt.show()\n",
    "        \n",
    "    return GP, policy_diffs, kernel_params\n",
    "\n",
    "def run_all_combinations():\n",
    "    num_per_comb = 27\n",
    "    performers = [\"bad_pitch\", \"balanced\", \"bad_timing\"]\n",
    "    noise_vars = [0.0, 0.25, 0.5] # [0.0, 0.1] #\n",
    "    bpm_norm_facs = [100] #1\n",
    "    \n",
    "    NUM_ROUNDS = 50\n",
    "    \n",
    "    comb = list()\n",
    "    for performer, noise_var, bpm_norm_fac in itertools.product(performers, \n",
    "                                                                 noise_vars,\n",
    "                                                                 bpm_norm_facs):\n",
    "        comb.extend([(performer, noise_var, bpm_norm_fac)]*num_per_comb)\n",
    "        \n",
    "    from multiprocessing import Pool\n",
    "    pool = Pool(2)\n",
    "    \n",
    "    import functools\n",
    "    single_exp = functools.partial(single_experiment_run_tup, \n",
    "                                             num_rounds=NUM_ROUNDS)\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    results = list()\n",
    "    for res in tqdm(pool.imap_unordered(single_exp, comb),\n",
    "                    total=len(comb),\n",
    "                    smoothing=0):\n",
    "    # for res in tqdm(map(single_exp, comb), # for debugging\n",
    "    #             total=len(comb),\n",
    "    #             smoothing=0):\n",
    "        results.append(res)\n",
    "        \n",
    "    res_dicts = list()\n",
    "    for run_idx, ((performer, noise_var, bpm_norm_fac), diffs) in enumerate(results):\n",
    "        pre_dict = dict(run_idx=run_idx,\n",
    "                        performer=performer,\n",
    "                        noise_var=noise_var,\n",
    "                        bpm_norm_fac=bpm_norm_fac)\n",
    "        for idx, val in enumerate(diffs):\n",
    "            d = pre_dict.copy()\n",
    "            d[\"iteration\"] = idx+1\n",
    "            d[\"policy_loss\"] = val\n",
    "            \n",
    "            res_dicts.append(d)\n",
    "            \n",
    "    return res_dicts\n",
    "        \n",
    "    \n",
    "def single_test_run():\n",
    "    STARTING_COMPLEXITY_LEVEL = 0\n",
    "    c = STARTING_COMPLEXITY_LEVEL\n",
    "    \n",
    "    performer = \"bad_timing\"\n",
    "    # performer = \"bad_pitch\"\n",
    "    # performer = \"balanced\"\n",
    "    \n",
    "    task_err_noise_var = 0.5\n",
    "    utility_noise_var  = 0.5\n",
    "     \n",
    "    TARGET_LOSS = 0.0\n",
    "    \n",
    "    for idx in range(100):\n",
    "        print(str(idx).center(64, \"=\"))\n",
    "        \n",
    "        GP, policy_diffs, kernel_params = single_experiment_run(\n",
    "            num_rounds=100, \n",
    "            performer=performer, \n",
    "            task_err_noise_var=task_err_noise_var, \n",
    "            utility_noise_var=utility_noise_var, \n",
    "            bpm_norm_fac=100,\n",
    "            plot=False,\n",
    "            print_details=True)\n",
    "        \n",
    "            \n",
    "        if policy_diffs[-1] >= TARGET_LOSS:\n",
    "            GP.plot_mutiple(c, [\n",
    "                \n",
    "                PracticeMode.IMP_TIMING,\n",
    "                PracticeMode.IMP_PITCH,\n",
    "                ])\n",
    "            \n",
    "            plt.plot(list(range(len(policy_diffs))), policy_diffs)\n",
    "            plt.ylim((-0.01,None))\n",
    "            plt.show()\n",
    "            \n",
    "            plt.plot(list(range(len(kernel_params))), kernel_params)\n",
    "            plt.legend([\"variance\", \"lengthscale\"])\n",
    "            plt.ylim((-0.01,None))\n",
    "            plt.show()\n",
    "            \n",
    "            break\n",
    "\n",
    "def run_combs_and_plot():\n",
    "    results = run_all_combinations()\n",
    "    \n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "    df = df.rename(columns={\"performer\": \"human-learner\"})\n",
    "\n",
    "    sns.relplot(\n",
    "        data=df,\n",
    "        x=\"iteration\", y=\"policy_loss\",\n",
    "        hue=\"noise_var\",\n",
    "        # hue=\"noise_var\",\n",
    "        col=\"human-learner\",\n",
    "        kind=\"line\",\n",
    "        ci=68,\n",
    "    )\n",
    "\n",
    "    # plt.ylim((None,0.8))\n",
    "    plt.xlim((1,50))\n",
    "    # plt.savefig(\"performers.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_diff_to_utility(error_pre_pitch, error_post_pitch, error_pre_timing, error_post_timing):\n",
    "    diff_timing = error_post_timing - error_pre_timing\n",
    "    diff_pitch  = error_post_pitch  - error_pre_pitch\n",
    "    \n",
    "    \n",
    "    MEAN_UTILITY = 0.75\n",
    "    \n",
    "    return - (diff_timing*1 + diff_pitch*1) - MEAN_UTILITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(sum_diff, length):\n",
    "        #start with avg diff, need to define loss\n",
    "        return sum_diff / length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_function(prediction, expert):\n",
    "    #get two vectors containing orederd predictions and expert data practice modes\n",
    "    diff = 0\n",
    "    for i, pred in enumerate(prediction):\n",
    "        if pred != expert[i]:\n",
    "            diff+=1\n",
    "    return loss(diff, len(prediction))\n",
    "    pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_diff(gauss_model, recorded_points, expert_practice_mode):\n",
    "         #calculate difference between the prediction of the gauss model and the expert advice.\n",
    "      r_p =  recorded_points[\"error_before_right_timing\", \"error_before_right_pitch\"]\n",
    "      #a question- the diff should be calculated binaricly(by prediction) or by the utility diffs?\n",
    "      policy_diff =diff_function(gauss_model.get_best_practice_mode(r_p),  expert_practice_mode)\n",
    "      return policy_diff\n",
    "      pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_diff_utility(gauss_model, point, expert_opt_policy):\n",
    "    \n",
    "      c=0#what is c?\n",
    "      policy_diff= compare_to_best_policy(gauss_model.get_policy(c),point[\"utility\"])\n",
    "      return policy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_diff_for_single_gp(gauss_model, recorded_points):\n",
    "    #calculate the policy diff for a single gp, given the recorded points and the expert decision\n",
    "    policy_diff = []*len(recorded_points)\n",
    "    practice_mode_map = {'IMP_PITCH': PracticeMode.IMP_PITCH, 'IMP_TIMING': PracticeMode.IMP_TIMING}\n",
    "    #for all recorded data points\n",
    "    for i, point in recorded_points.iterrows():\n",
    "        #differentiate between the data and the expert decision\n",
    "        point_data = point.drop(\"utility\")\n",
    "        expert_opt_policy = point[\"utility\"]\n",
    "        bpm = point[\"bpm\"]\n",
    "        #note_range = point[\"note_range\"]\n",
    "        note_range = NoteRangePerHand.MEDIUM\n",
    "        tp = TaskParameters(bpm=bpm, note_range=note_range)\n",
    "        given_practice_mode = point[\"practice_mode\"]\n",
    "       \n",
    "        my_practice_mode = practice_mode_map[given_practice_mode]\n",
    "        \n",
    "        complexity_level = 0\n",
    "        #add the data point to the gp\n",
    "        #articulate what is the note range supposed to be\n",
    "        gauss_model.add_data_point(complexity_level,tp, my_practice_mode, expert_opt_policy)#need to make sure that the data is in the right format. template:GP.add_data_point(c, tp, given_practice_mode, utility)\n",
    "        gauss_model.update_model()\n",
    "        \n",
    "        #calculate the policy diff for the current gp, for the current point\n",
    "        c=0#what is c?\n",
    "        #BUG!\n",
    "        #missing argument for the func: see bug\n",
    "        policy_diff[i]= compare_to_best_policy(gauss_model.get_policy(c),expert_opt_policy)\n",
    "    return policy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_diff_for_all_gauss_models(gauss_models, recorded_points):\n",
    "    policy_diff = []\n",
    "    #for each gp, we calculate the policy diff for each added data point\n",
    "    for i, gauss_model in enumerate(gauss_models):\n",
    "        policy_diff.append(policy_diff_for_single_gp(gauss_model, recorded_points))\n",
    "    #we retrun an array of arrays- array contains the policy diff for a single gp, for each added data point\n",
    "    return policy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_with_kernel(self, kernel):\n",
    "    #it seems possible to enter the kernel to the functionality...\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilize_gp():\n",
    "        gp_models = []\n",
    "        variance = [0.2, 0.5, 1]\n",
    "        lengthscale = [1, 2, 3]\n",
    "        alpha_list = [0.1, 0.5, 1]\n",
    "        #RBF kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "                #for each kernel, we initialize a gp model with different hyperparameters\n",
    "                #initial a gp instance\n",
    "                gp = GaussianProcess()\n",
    "                kernel = GPy.kern.RBF(input_dim=gp.space.model_dimensionality, \n",
    "                                variance=v, \n",
    "                                lengthscale=l)\n",
    "                gp.update_model_with_kernel(kernel)\n",
    "                gp_models.append(gp)\n",
    "        #MATERN52 kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "                #for each kernel, we initialize a gp model with different hyperparameters\n",
    "                #initial a gp instance\n",
    "                gp = GaussianProcess()\n",
    "                kernel = GPy.kern.Matern52(input_dim=gp.space.model_dimensionality, \n",
    "                              variance=v, \n",
    "                              lengthscale=l)\n",
    "                gp.update_model_with_kernel(kernel)\n",
    "                gp_models.append(gp)\n",
    "        #Rational Quadratic kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "                for alpha in alpha_list:\n",
    "                    # initialize a gp instance\n",
    "                    gp = GaussianProcess()\n",
    "                    kernel = GPy.kern.RatQuad(input_dim=gp.space.model_dimensionality, \n",
    "                                            variance=v, \n",
    "                                            lengthscale=l, \n",
    "                                            power=alpha)\n",
    "                    gp.update_model_with_kernel(kernel)\n",
    "                    gp_models.append(gp)\n",
    "\n",
    "\n",
    "        #linear kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "        # initialize a gp instance\n",
    "                gp = GaussianProcess()\n",
    "                kernel = GPy.kern.Linear(input_dim=gp.space.model_dimensionality, \n",
    "                                        variances=np.ones(gp.space.model_dimensionality)*v, \n",
    "                                        ARD=True, # set to True for Automatic Relevance Determination\n",
    "                                        )\n",
    "                kernel.lengthscale = np.ones(gp.space.model_dimensionality)*l\n",
    "                gp.update_model_with_kernel(kernel)\n",
    "                gp_models.append(gp)\n",
    "\n",
    "\n",
    "\n",
    "        return gp_models\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_gp_generelize():\n",
    "    #generelized to any number of kernels, not sure if possible\n",
    "    gp_models = []\n",
    "    kernel_hyper_params = [{'lengthscale': 1.0}, {'lengthscale': 0.5}, {'lengthscale': 2.0}]\n",
    "    kernels = [GPy.kern.Matern52, GPy.kern.Matern32, GPy.kern.RBF]\n",
    "\n",
    "    for kernel, hyper_params in zip(kernels, kernel_hyper_params):\n",
    "        for param in hyper_params:\n",
    "            # initialize a new kernel with the given hyperparameters\n",
    "            kernel_instance = kernel(input_dim=1, **param)\n",
    "\n",
    "            # initialize a new Gaussian process model with the current kernel\n",
    "            gp = GaussianProcess(kernel=kernel_instance)\n",
    "\n",
    "            gp_models.append(gp)\n",
    "\n",
    "    return gp_models\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_gp(gauss_models, policy_diff):\n",
    "    #calculate best gp from policy diff\n",
    "    #cost function- the avg of each gausian policy diff\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compare_to_best_policy() missing 1 required positional argument: 'best_error_diff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eladv\\OneDrive\\מסמכים\\research\\GP_OPTIMIZATION.ipynb Cell 19\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#we need to initilize the gp models with different hyperparameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m gauss_models \u001b[39m=\u001b[39m initilize_gp()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m policy_diff \u001b[39m=\u001b[39m policy_diff_for_all_gauss_models(gauss_models, recorded_points)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m best_gp \u001b[39m=\u001b[39m optimal_gp(gauss_models, policy_diff)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32mc:\\Users\\eladv\\OneDrive\\מסמכים\\research\\GP_OPTIMIZATION.ipynb Cell 19\u001b[0m in \u001b[0;36mpolicy_diff_for_all_gauss_models\u001b[1;34m(gauss_models, recorded_points)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#for each gp, we calculate the policy diff for each added data point\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, gauss_model \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(gauss_models):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     policy_diff\u001b[39m.\u001b[39mappend(policy_diff_for_single_gp(gauss_model, recorded_points))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#we retrun an array of arrays- array contains the policy diff for a single gp, for each added data point\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m policy_diff\n",
      "\u001b[1;32mc:\\Users\\eladv\\OneDrive\\מסמכים\\research\\GP_OPTIMIZATION.ipynb Cell 19\u001b[0m in \u001b[0;36mpolicy_diff_for_single_gp\u001b[1;34m(gauss_model, recorded_points)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m#calculate the policy diff for the current gp, for the current point\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     c\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\u001b[39m#what is c?\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     policy_diff[i]\u001b[39m=\u001b[39m compare_to_best_policy(gauss_model\u001b[39m.\u001b[39;49mget_policy(c),expert_opt_policy)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eladv/OneDrive/%D7%9E%D7%A1%D7%9E%D7%9B%D7%99%D7%9D/research/GP_OPTIMIZATION.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m policy_diff\n",
      "\u001b[1;31mTypeError\u001b[0m: compare_to_best_policy() missing 1 required positional argument: 'best_error_diff'"
     ]
    }
   ],
   "source": [
    "#gets a utility collumn for expert data\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "expert_data[\"utility\"] = expert_data.apply(lambda row: error_diff_to_utility(row[\"error_before_right_pitch\"],\n",
    "                                                                             row[\"error_after_right_pitch\"],\n",
    "                                                                             row[\"error_before_right_timing\"],\n",
    "                                                                             row[\"error_after_right_timing\"]),\n",
    "                                            axis=1)\n",
    "\n",
    "#currently just right timing and right pitch\n",
    "recorded_points = expert_data[[\"error_before_right_timing\", \"error_before_right_pitch\",\"practice_mode\", \"bpm\",\"note_range\", \"utility\"]]\n",
    "#we need to initilize the gp models with different hyperparameters\n",
    "gauss_models = initilize_gp()\n",
    "policy_diff = policy_diff_for_all_gauss_models(gauss_models, recorded_points)\n",
    "best_gp = optimal_gp(gauss_models, policy_diff)\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "print(\"Time elapsed: {:.2f} seconds\".format(time_elapsed))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DEBUGGING THE ADD DATA POINT PARAMETERS(CURRENTLY- TP)\n",
    "2. UNDERSTAND THE OPTIMIZATION PROCESS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3d1baa44583d8ec46d9c51771f1212390b5783b843e583a1bb6c33531f0efe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
