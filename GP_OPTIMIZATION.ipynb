{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "EXPERT_PATH = '..\\\\research\\data_expert_demo.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>username</th>\n",
       "      <th>practice_mode</th>\n",
       "      <th>bpm</th>\n",
       "      <th>error_before_left_timing</th>\n",
       "      <th>error_before_right_timing</th>\n",
       "      <th>error_before_left_pitch</th>\n",
       "      <th>error_before_right_pitch</th>\n",
       "      <th>error_after_left_timing</th>\n",
       "      <th>error_after_right_timing</th>\n",
       "      <th>error_after_left_pitch</th>\n",
       "      <th>error_after_right_pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>song1.mid</td>\n",
       "      <td>elad_demo_0</td>\n",
       "      <td>IMP_TIMING</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_TIMING</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     midi_filename      username practice_mode   bpm   \n",
       "0        song1.mid   elad_demo_0    IMP_TIMING  75.0  \\\n",
       "1  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "2  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "3  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "4  83b_HaAviv.midi  elad_demo_01    IMP_TIMING  85.0   \n",
       "\n",
       "   error_before_left_timing  error_before_right_timing   \n",
       "0                       0.0                   0.036429  \\\n",
       "1                       0.0                   0.078066   \n",
       "2                       0.0                   0.049352   \n",
       "3                       0.0                   0.040376   \n",
       "4                       0.0                   0.021390   \n",
       "\n",
       "   error_before_left_pitch  error_before_right_pitch  error_after_left_timing   \n",
       "0                      0.0                  0.000000                      0.0  \\\n",
       "1                      0.0                  0.152778                      0.0   \n",
       "2                      0.0                  0.250000                      0.0   \n",
       "3                      0.0                  0.013889                      0.0   \n",
       "4                      0.0                  0.000000                      0.0   \n",
       "\n",
       "   error_after_right_timing  error_after_left_pitch  error_after_right_pitch  \n",
       "0                  0.030571                     0.0                 0.000000  \n",
       "1                  0.049352                     0.0                 0.250000  \n",
       "2                  0.040376                     0.0                 0.013889  \n",
       "3                  0.021390                     0.0                 0.000000  \n",
       "4                  0.017971                     0.0                 0.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data = pd.read_hdf(EXPERT_PATH)\n",
    "expert_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Error = namedtuple(\"Error\", \"pitch timing\")\n",
    "\n",
    "BPM_BOUNDS = [50,200]\n",
    "\n",
    "#### SIMPLIFIED ENUMS\n",
    "import enum\n",
    "class PracticeMode(enum.Enum):\n",
    "    IMP_PITCH = enum.auto()\n",
    "    IMP_TIMING = enum.auto()\n",
    "    \n",
    "class NoteRangePerHand(enum.Enum):\n",
    "    EASY = 0.5\n",
    "    MEDIUM = 1.5\n",
    "    HARD = 3.0\n",
    "    \n",
    "\n",
    "import dataclasses as dc\n",
    "from dataclasses import dataclass, astuple    \n",
    "@dataclass\n",
    "class TaskParameters:\n",
    "    \"\"\"\n",
    "    We need to redefine this to use the new, simplified NoteRangePerHand.\n",
    "    \n",
    "    \n",
    "    TODO: Should we include the parameters we are not using here?\n",
    "        maybe just clarify which one we are using in this simplified case\n",
    "    \"\"\"\n",
    "    \n",
    "    ## USED IN SIMPLIFIED CASE\n",
    "    bpm: float              = 120\n",
    "    note_range: NoteRangePerHand = NoteRangePerHand.MEDIUM\n",
    "    \n",
    "    ## UNUSED HERE, but used in real application\n",
    "    timeSignature: tuple    = (4,4)\n",
    "    noteValues: list        = dc.field(default_factory= lambda: [1, 1 / 2, 1 / 4, 1 / 8] )\n",
    "    maxNotesPerBar: int       = 3\n",
    "    noOfBars: int           = 7\n",
    "    note_range: NoteRangePerHand = NoteRangePerHand.MEDIUM\n",
    "    left: bool              = False\n",
    "    right: bool             = True\n",
    "    \n",
    "    \n",
    "    def astuple(self):\n",
    "        return astuple(self)\n",
    "    \n",
    "\n",
    "## Mappings of categorical data to ints.\n",
    "### The pracice modes will be mapped onto a single dimension, placed far away\n",
    "### from each other\n",
    "practicemode2int = {pm: i*1000 for i, pm in enumerate(PracticeMode)}\n",
    "int2practicemode = {i*1000: pm for i, pm in enumerate(PracticeMode)}\n",
    "    \n",
    "### The note range will be one-hot encoded, but we still need dicts to convert\n",
    "noterange2int = {pm: i for i, pm in enumerate(NoteRangePerHand)}\n",
    "int2noterange = {i: pm for i, pm in enumerate(NoteRangePerHand)}\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import GPyOpt\n",
    "import GPy\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPPlotData:\n",
    "    X1: np.array = None\n",
    "    X2: np.array = None\n",
    "    mean: np.array = None \n",
    "    mean_max: float = None\n",
    "    mean_min: float = None\n",
    "    std: np.array = None\n",
    "    std_max: float = None\n",
    "    std_min: float = None\n",
    "    acq: np.array = None\n",
    "    acq_max: float = None\n",
    "    acq_min: float = None\n",
    "    \n",
    "    def apply_to_arrays(self, func):\n",
    "        return [\n",
    "            func(self.mean),\n",
    "            func(self.std),\n",
    "            func(self.acq),\n",
    "            ]\n",
    "\n",
    "\n",
    "class GaussianProcess:\n",
    "    def __init__(self, bpm_norm_fac=100):\n",
    "        self.data_X = None#should be the task parameters\n",
    "        self.data_X_old_shape = None\n",
    "        \n",
    "        self.data_Y = None#should be the error after\n",
    "        \n",
    "        self.bpm_norm_fac = bpm_norm_fac\n",
    "        \n",
    "        self.domain =[\n",
    "            {'name': 'complexity_level', 'type': 'discrete', 'domain': tuple(range(10))},\n",
    "            {'name': 'practice_mode', 'type': 'discrete', 'domain': tuple(i*1000 for i , _ in enumerate(PracticeMode))},\n",
    "            {'name': 'note_range', 'type': 'categorical', 'domain': (0,1,2)},\n",
    "            {'name': 'bpm', 'type': 'continuous', 'domain': \n",
    "                 (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))},\n",
    "                 \n",
    "                ]\n",
    "                 \n",
    "       \n",
    "        self.space = GPyOpt.core.task.space.Design_space(self.domain)\n",
    "        \n",
    "    def _norm_bpm(self, v):\n",
    "        return v/self.bpm_norm_fac\n",
    "        \n",
    "    def _params2domain(self, complexity_level, task_parameters, practice_mode):\n",
    "        domain_x = [complexity_level,\n",
    "                    practicemode2int[practice_mode],\n",
    "                    noterange2int[task_parameters.note_range],\n",
    "                    self._norm_bpm(task_parameters.bpm),\n",
    "                    ]\n",
    "        \n",
    "        \n",
    "        return np.array([domain_x])\n",
    "        \n",
    "    def _domain2space(self, domain_x):\n",
    "        ## Converts the domain variables into the GPs input space\n",
    "        ## does one-hot encoding\n",
    "        space_rep = self.space.unzip_inputs(domain_x)\n",
    "        return space_rep\n",
    "    \n",
    "        \n",
    "    def _get_bayes_opt(self):\n",
    "        return self.bayes_opt\n",
    "        \n",
    "    \n",
    "    def update_model(self):\n",
    "\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        # kernel = GPy.kern.RBF(input_dim=self.space.model_dimensionality, \n",
    "        #                       variance=0.01, \n",
    "        #                       lengthscale=1)\n",
    "\n",
    "\n",
    "        #here to add modularity- different kernels for different  hyperparameters\n",
    "        \n",
    "        kernel = GPy.kern.Matern52(input_dim=self.space.model_dimensionality, \n",
    "                              variance=0.01, \n",
    "                              lengthscale=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt._update_model() \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt._update_model() \n",
    "        \n",
    "#experimental\n",
    "\n",
    "    def update_model_with_kernel(self, kernel):\n",
    "    #it seems possible to enter the kernel to the functionality...\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        \n",
    "        \n",
    "    #sort of predict that gives utility\n",
    "    def get_estimate(self, complexity_level, task_parameters, practice_mode,\n",
    "                     add_variance=True):\n",
    "        if not hasattr(self, \"bayes_opt\"):\n",
    "            # if there is no model yet, e.g. in the first iteration\n",
    "            # print(\"(GP) DATA_X IS NONE, RETURNING RANDOM NUMBER\")\n",
    "            return random.random()\n",
    "        \n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        X = self._params2domain(complexity_level, task_parameters, practice_mode)\n",
    "        X = self._domain2space(X)\n",
    "        \n",
    "        mean, var = bayes_opt.model.predict(X)\n",
    "        \n",
    "        r = mean[0]\n",
    "        if add_variance:\n",
    "            r += np.sqrt(var[0])\n",
    "        return r\n",
    "        \n",
    "    #choose the best practice mode from utility estimate\n",
    "    def get_best_practice_mode(self, complexity_level, task_parameters):\n",
    "        all_practice_modes = list(PracticeMode)\n",
    "        if random.random() > 0.05:\n",
    "            max_i = np.argmax([self.get_estimate(complexity_level, task_parameters, pm)\n",
    "                                             for pm in all_practice_modes])\n",
    "            return all_practice_modes[max_i]\n",
    "        \n",
    "        else:\n",
    "            # use weighted choice based on softmax\n",
    "            # increases exploration\n",
    "            def softmax(x):\n",
    "                return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            \n",
    "            return random.choices(all_practice_modes, \n",
    "                                  softmax(\n",
    "                [0.5*self.get_estimate(complexity_level, task_parameters, pm)\n",
    "                                             for pm in all_practice_modes]), k=1)[0]\n",
    "            \n",
    "    \n",
    "    def add_data_point(self, complexity_level, task_parameters, practice_mode, \n",
    "                       utility_measurement):\n",
    "        new_x =  self._params2domain(complexity_level, task_parameters, practice_mode) \n",
    "        new_y = [ utility_measurement ]\n",
    "        \n",
    "        if self.data_X is None:\n",
    "            self.data_X = new_x\n",
    "            self.data_Y = [new_y]\n",
    "        else:\n",
    "            self.data_X = np.vstack((self.data_X, new_x[0]))\n",
    "            self.data_Y = np.vstack((self.data_Y, new_y[0]))\n",
    "    \n",
    "    def get_policy(self, c):\n",
    "        if not hasattr(self, \"bayes_opt\"):\n",
    "            return np.round(np.random.random((3*150,1)))\n",
    "        \n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        data_dict = defaultdict(GPPlotData)\n",
    "        for i, practice_mode in enumerate([PracticeMode.IMP_TIMING,\n",
    "                                           PracticeMode.IMP_PITCH]):\n",
    "            # insert plot data into the data_dict\n",
    "            self._get_plot_data(data_dict, c, practice_mode, bayes_opt)\n",
    "            \n",
    "        return np.argmax([d.mean for d in [\n",
    "            data_dict[PracticeMode.IMP_TIMING], data_dict[PracticeMode.IMP_PITCH]]], axis=0)\n",
    "    #add on\n",
    "    def get_current_kernel(self):\n",
    "        if not hasattr(self, \"bayes_opt\"):\n",
    "            return None\n",
    "        return self.bayes_opt.model.model.kern\n",
    "\n",
    "        \n",
    "    def _get_plot_data(self, data_dict, c, practice_mode, bayes_opt, for_plot=False):\n",
    "        bounds = [[0,3], (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))]\n",
    "        \n",
    "        acquisition_function = bayes_opt.acquisition.acquisition_function\n",
    "        model = bayes_opt.model\n",
    "        \n",
    "        if not for_plot:\n",
    "            X1 = np.array([0,1,2])\n",
    "            X1_axis = X1\n",
    "            reshape_dim = 3*150\n",
    "        else:\n",
    "            X1_axis = np.linspace(bounds[0][0], bounds[0][1], 150, endpoint=False)\n",
    "            X1 = np.array([0]*50 + [1]*50 + [2]*50)\n",
    "            reshape_dim = 150*150\n",
    "            \n",
    "        X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "        \n",
    "        x1, x2 = np.meshgrid(X1, X2)\n",
    "        X = np.hstack((\n",
    "            \n",
    "            np.array([c]*(reshape_dim)).reshape(reshape_dim,1),\n",
    "            np.array([practicemode2int[practice_mode]]*(reshape_dim)).reshape(reshape_dim,1),\n",
    "            x1.reshape(reshape_dim,1),\n",
    "             x2.reshape(reshape_dim,1)))\n",
    "        \n",
    "        X_spaced = self._domain2space(X)\n",
    "         \n",
    "        acqu = acquisition_function(X_spaced)\n",
    "        \n",
    "        m, v = model.predict(X_spaced)\n",
    "        \n",
    "        if type(m) == list:\n",
    "            m = m[0]\n",
    "        \n",
    "        if type(v) == list:\n",
    "            v = v[0]\n",
    "        \n",
    "        if type(acqu) == list:\n",
    "            acqu = acqu[0]\n",
    "        \n",
    "        data_dict[practice_mode].mean = m\n",
    "        data_dict[practice_mode].std = np.sqrt(v)\n",
    "        data_dict[practice_mode].acq = acqu\n",
    "        data_dict[practice_mode].X1 = X1_axis\n",
    "        data_dict[practice_mode].X2 = X2\n",
    "        \n",
    "    \n",
    "    def _plot_single_practice_mode(self, gp_plot_data, subplotf,\n",
    "                                   plot_mean=True,\n",
    "                                   plot_std=True,\n",
    "                                   plot_acq=True):\n",
    "        label_x = \"NoteRange\"\n",
    "        label_y = \"BPM\"\n",
    "        \n",
    "        X_TICKS = ([0.5,1.5,2.5], [\"0\", \"1\", \"2\"])\n",
    "        \n",
    "        bounds = [[0,3], (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))]\n",
    "        \n",
    "        ## Derived from GPyOpt/plotting/plots_bo.py\n",
    "        X1 = gp_plot_data.X1\n",
    "        X2 = gp_plot_data.X2\n",
    "        \n",
    "        def inflate_array(a):\n",
    "            return a.reshape((150,150))\n",
    "        \n",
    "        subplot_count = 0\n",
    "        \n",
    "        if plot_mean:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.mean),100,\n",
    "                         vmin=gp_plot_data.mean_min,\n",
    "                         vmax=gp_plot_data.mean_max,)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Posterior mean')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "        ##\n",
    "        \n",
    "        if plot_std:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.std),100,\n",
    "                         vmin=gp_plot_data.std_min,\n",
    "                         vmax=gp_plot_data.std_max)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Posterior sd.')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "        ##\n",
    "        \n",
    "        \n",
    "        if plot_acq:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.acq),100,\n",
    "                         vmin=gp_plot_data.acq_min,\n",
    "                         vmax=gp_plot_data.acq_max,)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Acquisition function')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "            \n",
    "    \n",
    "    def plot_mutiple(self, c, practice_modes,\n",
    "                                   plot_mean=True,\n",
    "                                   plot_std=True,\n",
    "                                   plot_acq=False):\n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        n_rows = len(practice_modes)\n",
    "        n_cols = sum([plot_mean, plot_std, plot_acq])\n",
    "        \n",
    "        data_dict = defaultdict(GPPlotData)\n",
    "        for i, practice_mode in enumerate(practice_modes):\n",
    "            self._get_plot_data(data_dict, c, practice_mode, bayes_opt,\n",
    "                                for_plot=True)\n",
    "            \n",
    "        mean_max, std_max, acq_max = np.max([d.apply_to_arrays(np.max) for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        mean_min, std_min, acq_min = np.min([d.apply_to_arrays(np.min) for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        for pd in data_dict.values():\n",
    "            pd.mean_max = mean_max\n",
    "            pd.mean_min = mean_min\n",
    "            pd.std_max = std_max\n",
    "            pd.std_min = std_min\n",
    "            pd.acq_max = acq_max\n",
    "            pd.acq_min = acq_min\n",
    "        \n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(n_cols*3.34,5*n_rows))\n",
    "        \n",
    "        for i, practice_mode in enumerate(practice_modes):\n",
    "            subplotf = lambda idx: plt.subplot(n_rows,n_cols,i*n_cols+idx)\n",
    "            self._plot_single_practice_mode(data_dict[practice_mode], subplotf,\n",
    "                                            plot_mean=plot_mean,\n",
    "                                            plot_std=plot_std,\n",
    "                                            plot_acq=plot_acq)\n",
    "            \n",
    "            ax = subplotf(1)\n",
    "            row = practice_mode.name\n",
    "            pad = 5\n",
    "            ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                        xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                        size='large', ha='right', va='center')\n",
    "        \n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.savefig(\"detailed_noise05.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        some_pd = list(data_dict.values())[0]\n",
    "        \n",
    "        argmax_plot_data = GPPlotData(X1=some_pd.X1, X2=some_pd.X2)\n",
    "        argmax_plot_data.mean = np.argmax([d.mean for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        argmax_plot_data.std = np.argmax([d.std for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        argmax_plot_data.acq = np.argmax([d.acq for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        subplotf = lambda idx: plt.subplot(1,3,idx)\n",
    "        \n",
    "        self._plot_single_practice_mode(argmax_plot_data, subplotf)\n",
    "        ax = subplotf(1)\n",
    "        row = \"ARGMAX\"\n",
    "        pad = 5\n",
    "        ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                    xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                    size='large', ha='right', va='center')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def gen_tasks(num_tasks=None, seed=546354):\n",
    "    assert num_tasks != None\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    for i in range(num_tasks):\n",
    "        bpm = rng.integers(*BPM_BOUNDS) \n",
    "        note_range = rng.choice(NoteRangePerHand)\n",
    "    \n",
    "        yield TaskParameters(bpm=bpm, note_range=note_range)\n",
    "    \n",
    "def task2error(task_parameters):\n",
    "    return Error(pitch=task_parameters.note_range.value,\n",
    "                timing=task_parameters.bpm/100\n",
    "                 )\n",
    "\n",
    "def task2error2(np_array):\n",
    "    def note_range_map(v):\n",
    "        import math\n",
    "        return [NoteRangePerHand.EASY.value, NoteRangePerHand.MEDIUM.value, \n",
    "                NoteRangePerHand.HARD.value][int(math.floor(v))]\n",
    "    \n",
    "    out = [[note_range_map(nr), bpm/100] for nr, bpm in np_array]\n",
    "    return np.array(out)\n",
    "\n",
    "    \n",
    "def per_after_practice(practice_mode, error):\n",
    "    if practice_mode == PracticeMode.IMP_PITCH:\n",
    "        return perf_after_pitch_practice(error)\n",
    "    if practice_mode == PracticeMode.IMP_TIMING:\n",
    "        return perf_after_timing_practice(error)\n",
    "    raise Exception()\n",
    "\n",
    "def perf_after_pitch_practice(error):\n",
    "    return Error(timing=error.timing,\n",
    "                 pitch=error.pitch*0.5)\n",
    "\n",
    "def perf_after_timing_practice(error):\n",
    "    return Error(timing=error.timing*0.5,\n",
    "                 pitch=error.pitch)\n",
    "\n",
    "def error_diff_to_utility(error_pre, error_post):\n",
    "    diff_timing = error_post.timing - error_pre.timing\n",
    "    diff_pitch  = error_post.pitch  - error_pre.pitch\n",
    "    \n",
    "    \n",
    "    MEAN_UTILITY = 0.75\n",
    "    \n",
    "    return - (diff_timing*1 + diff_pitch*1) - MEAN_UTILITY\n",
    "\n",
    "\n",
    "def calc_optimal_policy(performance):\n",
    "    bounds = [[0,3], BPM_BOUNDS]\n",
    "            \n",
    "    X1 = np.array([0,1,2])\n",
    "    X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "    x1, x2 = np.meshgrid(X1, X2)\n",
    "    X = np.hstack((    \n",
    "         x1.reshape(3*150,1),\n",
    "          x2.reshape(3*150,1)))\n",
    "    \n",
    "    error2d = task2error2(X)\n",
    "    error2d = np.array([performance(Error(*err)) for err in error2d])\n",
    "    \n",
    "    err_post_pitch = np.array(\n",
    "        [perf_after_pitch_practice(Error(*err)) for err in error2d])\n",
    "    \n",
    "    err_post_timing = np.array(\n",
    "        [perf_after_timing_practice(Error(*err)) for err in error2d])\n",
    "    \n",
    "    \n",
    "    argmax = np.argmin(np.vstack((\n",
    "        np.sum(err_post_timing, axis=1),\n",
    "        np.sum(err_post_pitch, axis=1)\n",
    "        )), axis=0)\n",
    "    \n",
    "    \n",
    "    error_diff = np.array([timing-pitch for timing, pitch in\n",
    "                          zip(\n",
    "        np.sum(err_post_timing, axis=1),\n",
    "        np.sum(err_post_pitch, axis=1))])\n",
    "    \n",
    "    return argmax.reshape(3*150,1), np.abs(error_diff.reshape(3*150,1))\n",
    "\n",
    "def compare_to_best_policy(policy_argmax, best_argmax, best_error_diff=1):\n",
    "    num_diff_cases = np.sum(np.abs(policy_argmax-best_argmax))\n",
    "    \n",
    "    abs_diff = num_diff_cases / policy_argmax.shape[0]\n",
    "    #weighted_diff = np.sum(best_error_diff[policy_argmax!=best_argmax]) / \\\n",
    "     #                       (np.median(best_error_diff) * best_error_diff.shape[0])\n",
    "    \n",
    "    return abs_diff #, weighted_diff\n",
    "\n",
    "def plot_best_policy():\n",
    "    label_x = \"NoteRange\"\n",
    "    label_y = \"BPM\"\n",
    "    \n",
    "    bounds = [[0,3], BPM_BOUNDS]\n",
    "    X_TICKS = ([0.5,1.5,2.5], [\"0\", \"1\", \"2\"])\n",
    "    \n",
    "    X1 = np.linspace(bounds[0][0], bounds[0][1], 150, endpoint=False)\n",
    "    X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "    x1, x2 = np.meshgrid(X1, X2)\n",
    "    X = np.hstack((    \n",
    "         x1.reshape(150*150,1),\n",
    "          x2.reshape(150*150,1)))\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    for idx, performance in enumerate([perf_bad_pitch, perf_balanced,\n",
    "                                       perf_bad_timing]):\n",
    "        title = [\"Bad Pitch\", \"Balanced\", \"Bad Timing\"][idx]\n",
    "        \n",
    "        error2d = task2error2(X)\n",
    "        error2d = np.array([performance(Error(*err)) for err in error2d])\n",
    "        \n",
    "        err_post_pitch = np.array(\n",
    "            [perf_after_pitch_practice(Error(*err)) for err in error2d])\n",
    "        \n",
    "        err_post_timing = np.array(\n",
    "            [perf_after_timing_practice(Error(*err)) for err in error2d])\n",
    "        \n",
    "        \n",
    "        argmax = np.argmin(np.vstack((\n",
    "            np.sum(err_post_timing, axis=1),\n",
    "            np.sum(err_post_pitch, axis=1)\n",
    "            )), axis=0)\n",
    "        \n",
    "        \n",
    "        plt.subplot(1, 3, idx+1)\n",
    "        plt.contourf(X1, X2, argmax.reshape(150,150),50,)\n",
    "        plt.xlabel(label_x)\n",
    "        if idx == 0:\n",
    "            plt.ylabel(label_y)\n",
    "        plt.title(title)\n",
    "        plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "        plt.xticks(*X_TICKS)\n",
    "        \n",
    "        if idx == 0:\n",
    "            from matplotlib.patches import Patch\n",
    "            cmap = plt.cm.viridis\n",
    "            custom_lines = [Patch(facecolor=cmap(1.)),\n",
    "                        Patch(facecolor=cmap(0.)),]\n",
    "            plt.legend(custom_lines, [\"IMP_PITCH\", \"IMP_TIMING\"])\n",
    "        \n",
    "    # plt.savefig(\"optimal_policies.eps\")\n",
    "    plt.show()\n",
    "    \n",
    "def single_experiment_run_tup(inp_tup, num_rounds):\n",
    "        performer, noise_var, bpm_norm_fac = inp_tup\n",
    "        gp, policy_diffs, kernel_params = single_experiment_run(\n",
    "                                    num_rounds=num_rounds, \n",
    "                                    performer=performer, \n",
    "                                    task_err_noise_var=noise_var, \n",
    "                                    utility_noise_var=noise_var, \n",
    "                                    bpm_norm_fac=bpm_norm_fac)\n",
    "        return (performer, noise_var, bpm_norm_fac), policy_diffs\n",
    "\n",
    "def single_experiment_run(num_rounds, \n",
    "                          performer, \n",
    "                          task_err_noise_var, utility_noise_var,\n",
    "                          bpm_norm_fac,\n",
    "                          seed=None,\n",
    "                          plot=False,\n",
    "                          print_details=False):\n",
    "    \n",
    "    if print_details:\n",
    "        from tqdm import tqdm\n",
    "    else:\n",
    "        def tqdm(iterable, **kwargs):\n",
    "            for x in iterable:\n",
    "                yield(x)\n",
    "    \n",
    "    seed = seed or random.randint(0, 2**16)\n",
    "    \n",
    "    performance_dict = dict(bad_pitch=perf_bad_pitch,\n",
    "                            balanced=perf_balanced,\n",
    "                            bad_timing=perf_bad_timing)\n",
    "    \n",
    "    perf_string = str(performer)\n",
    "    performer = performance_dict[perf_string]\n",
    "    \n",
    "    best_policy = calc_optimal_policy(performer)\n",
    "    policy_diffs = list()\n",
    "    kernel_params = list()\n",
    "    \n",
    "    GP = GaussianProcess(bpm_norm_fac=bpm_norm_fac)\n",
    "    c = 0\n",
    "    \n",
    "    for idx, tp in enumerate(tqdm(gen_tasks(num_rounds, seed=seed), \n",
    "                                  total=num_rounds)):\n",
    "        if idx % 3 == 0:\n",
    "            _pre = time.time()\n",
    "            \n",
    "            GP.update_model()\n",
    "            policy_diff = compare_to_best_policy(GP.get_policy(c),\n",
    "                *best_policy)\n",
    "            \n",
    "        \n",
    "        if hasattr(GP, \"bayes_opt\"):\n",
    "            kernel_params.append(list(map(lambda a:a.values[0],\n",
    "                    GP.bayes_opt.model.model.kern.parameters)))\n",
    "        \n",
    "        policy_diffs.append(policy_diff[1]) # only use weighted diff \n",
    "        \n",
    "        task_error = task2error(tp)\n",
    "        \n",
    "        task_error = Error(\n",
    "            pitch=task_error.pitch* random.gauss(1,task_err_noise_var),\n",
    "            timing=task_error.timing* random.gauss(1,task_err_noise_var),)\n",
    "        \n",
    "        \n",
    "        error_pre = performer(task_error)\n",
    "        given_practice_mode = GP.get_best_practice_mode(c, tp)\n",
    "        error_post = per_after_practice(given_practice_mode, error_pre)\n",
    "        utility = error_diff_to_utility(error_pre, error_post)\n",
    "        \n",
    "        utility *= random.gauss(1,utility_noise_var)\n",
    "        \n",
    "        GP.add_data_point(c, tp, given_practice_mode, utility)\n",
    "        \n",
    "        if print_details:\n",
    "            tqdm.write(\"\\n\")\n",
    "            tqdm.write(f\"NoteRange = {tp.note_range}\")\n",
    "            tqdm.write(f\"BPM = {tp.bpm}\")\n",
    "            tqdm.write(f\"Suggested PracticeMode: {given_practice_mode}\")\n",
    "            tqdm.write(f\"Error Pre: {error_pre}\")\n",
    "            tqdm.write(f\"Error post: {error_post}\")\n",
    "            tqdm.write(f\"Utility: {utility}\")\n",
    "            tqdm.write(f\"Policy Diff: {policy_diff}\")\n",
    "            tqdm.write(\"-\"*32)\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        GP.plot_mutiple(c, [\n",
    "            \n",
    "            PracticeMode.IMP_TIMING,\n",
    "            PracticeMode.IMP_PITCH,\n",
    "            ])\n",
    "        \n",
    "        plt.plot(list(range(len(policy_diffs))), policy_diffs)\n",
    "        plt.ylim((-0.01,None))\n",
    "        plt.show()\n",
    "        \n",
    "    return GP, policy_diffs, kernel_params\n",
    "\n",
    "def run_all_combinations():\n",
    "    num_per_comb = 27\n",
    "    performers = [\"bad_pitch\", \"balanced\", \"bad_timing\"]\n",
    "    noise_vars = [0.0, 0.25, 0.5] # [0.0, 0.1] #\n",
    "    bpm_norm_facs = [100] #1\n",
    "    \n",
    "    NUM_ROUNDS = 50\n",
    "    \n",
    "    comb = list()\n",
    "    for performer, noise_var, bpm_norm_fac in itertools.product(performers, \n",
    "                                                                 noise_vars,\n",
    "                                                                 bpm_norm_facs):\n",
    "        comb.extend([(performer, noise_var, bpm_norm_fac)]*num_per_comb)\n",
    "        \n",
    "    from multiprocessing import Pool\n",
    "    pool = Pool(2)\n",
    "    \n",
    "    import functools\n",
    "    single_exp = functools.partial(single_experiment_run_tup, \n",
    "                                             num_rounds=NUM_ROUNDS)\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    results = list()\n",
    "    for res in tqdm(pool.imap_unordered(single_exp, comb),\n",
    "                    total=len(comb),\n",
    "                    smoothing=0):\n",
    "    # for res in tqdm(map(single_exp, comb), # for debugging\n",
    "    #             total=len(comb),\n",
    "    #             smoothing=0):\n",
    "        results.append(res)\n",
    "        \n",
    "    res_dicts = list()\n",
    "    for run_idx, ((performer, noise_var, bpm_norm_fac), diffs) in enumerate(results):\n",
    "        pre_dict = dict(run_idx=run_idx,\n",
    "                        performer=performer,\n",
    "                        noise_var=noise_var,\n",
    "                        bpm_norm_fac=bpm_norm_fac)\n",
    "        for idx, val in enumerate(diffs):\n",
    "            d = pre_dict.copy()\n",
    "            d[\"iteration\"] = idx+1\n",
    "            d[\"policy_loss\"] = val\n",
    "            \n",
    "            res_dicts.append(d)\n",
    "            \n",
    "    return res_dicts\n",
    "        \n",
    "    \n",
    "def single_test_run():\n",
    "    STARTING_COMPLEXITY_LEVEL = 0\n",
    "    c = STARTING_COMPLEXITY_LEVEL\n",
    "    \n",
    "    performer = \"bad_timing\"\n",
    "    # performer = \"bad_pitch\"\n",
    "    # performer = \"balanced\"\n",
    "    \n",
    "    task_err_noise_var = 0.5\n",
    "    utility_noise_var  = 0.5\n",
    "     \n",
    "    TARGET_LOSS = 0.0\n",
    "    \n",
    "    for idx in range(100):\n",
    "        print(str(idx).center(64, \"=\"))\n",
    "        \n",
    "        GP, policy_diffs, kernel_params = single_experiment_run(\n",
    "            num_rounds=100, \n",
    "            performer=performer, \n",
    "            task_err_noise_var=task_err_noise_var, \n",
    "            utility_noise_var=utility_noise_var, \n",
    "            bpm_norm_fac=100,\n",
    "            plot=False,\n",
    "            print_details=True)\n",
    "        \n",
    "            \n",
    "        if policy_diffs[-1] >= TARGET_LOSS:\n",
    "            GP.plot_mutiple(c, [\n",
    "                \n",
    "                PracticeMode.IMP_TIMING,\n",
    "                PracticeMode.IMP_PITCH,\n",
    "                ])\n",
    "            \n",
    "            plt.plot(list(range(len(policy_diffs))), policy_diffs)\n",
    "            plt.ylim((-0.01,None))\n",
    "            plt.show()\n",
    "            \n",
    "            plt.plot(list(range(len(kernel_params))), kernel_params)\n",
    "            plt.legend([\"variance\", \"lengthscale\"])\n",
    "            plt.ylim((-0.01,None))\n",
    "            plt.show()\n",
    "            \n",
    "            break\n",
    "\n",
    "def run_combs_and_plot():\n",
    "    results = run_all_combinations()\n",
    "    \n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "    df = df.rename(columns={\"performer\": \"human-learner\"})\n",
    "\n",
    "    sns.relplot(\n",
    "        data=df,\n",
    "        x=\"iteration\", y=\"policy_loss\",\n",
    "        hue=\"noise_var\",\n",
    "        # hue=\"noise_var\",\n",
    "        col=\"human-learner\",\n",
    "        kind=\"line\",\n",
    "        ci=68,\n",
    "    )\n",
    "\n",
    "    # plt.ylim((None,0.8))\n",
    "    plt.xlim((1,50))\n",
    "    # plt.savefig(\"performers.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_diff_to_utility_for_opt(error_pre_pitch, error_post_pitch, error_pre_timing, error_post_timing, a=1):\n",
    "    diff_timing = error_post_timing - error_pre_timing\n",
    "    diff_pitch  = error_post_pitch  - error_pre_pitch\n",
    "    \n",
    "    \n",
    "    MEAN_UTILITY = 0.75\n",
    "    \n",
    "    return - (diff_timing*a + diff_pitch*(1-a)) - MEAN_UTILITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_diff_for_single_gp(gauss_model, recorded_points):\n",
    "    #calculate the policy diff for a single gp, given the recorded points and the expert decision\n",
    "    policy_diff = []\n",
    "    practice_mode_map = {'IMP_PITCH': PracticeMode.IMP_PITCH, 'IMP_TIMING': PracticeMode.IMP_TIMING}\n",
    "    #for all recorded data points\n",
    "    for i, point in recorded_points.iterrows():\n",
    "\n",
    "        #prepare the data in the right format for adding to the gp\n",
    "\n",
    "        point_data = point.drop(\"utility\")\n",
    "        expert_opt_policy = point[\"utility\"]\n",
    "        note_range = NoteRangePerHand.MEDIUM\n",
    "        tp = TaskParameters(bpm=point[\"bpm\"], note_range=note_range)\n",
    "        given_practice_mode = point[\"practice_mode\"]\n",
    "        my_practice_mode = practice_mode_map[given_practice_mode]\n",
    "        complexity_level = 0\n",
    "\n",
    "        #add the data point to the gp\n",
    "    \n",
    "        gauss_model.add_data_point(complexity_level,tp, my_practice_mode, expert_opt_policy)\n",
    "        gauss_model.update_model()\n",
    "        \n",
    "        #calculate the policy diff for the current gp, for the current point\n",
    "        \n",
    "        c=0#what is c?\n",
    "        curr_diff = compare_to_best_policy(gauss_model.get_policy(c),expert_opt_policy)\n",
    "        #print(curr_diff)\n",
    "        policy_diff.append(curr_diff)\n",
    "    print(mean(policy_diff))\n",
    "    return policy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_with_kernel(self, kernel):\n",
    "    #it seems possible to enter the kernel to the functionality...\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_gp(gauss_models, policy_diff):\n",
    "    #we choose the gp with the lowest mean policy diff\n",
    "    best_model_index = np.argmin([np.mean(pd) for pd in policy_diff])\n",
    "    best_model = gauss_models[best_model_index]\n",
    "    return best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "def objective_function(x, kernel_type):\n",
    "    if x.ndim > 1:\n",
    "        x = x.flatten()\n",
    "    # x is a list of hyperparameters\n",
    "    if kernel_type == 'RatQuad':\n",
    "        variance, lengthscale, alpha = x[0], x[1], x[2]\n",
    "    else:\n",
    "        variance, lengthscale = x[0], x[1]\n",
    "    \n",
    "    # Initialize a GP model with the given hyperparameters and kernel type\n",
    "    gp = GaussianProcess()\n",
    "    if kernel_type == 'Matern52':\n",
    "        kernel = GPy.kern.Matern52(input_dim=gp.space.model_dimensionality, \n",
    "                                   variance=variance, \n",
    "                                   lengthscale=lengthscale)\n",
    "    elif kernel_type == 'linear':\n",
    "        kernel = GPy.kern.Linear(input_dim=gp.space.model_dimensionality,\n",
    "                                 variances=variance)\n",
    "    elif kernel_type == 'RatQuad':\n",
    "        kernel = GPy.kern.RatQuad(input_dim=gp.space.model_dimensionality,\n",
    "                                    variance=variance,\n",
    "                                    lengthscale=lengthscale,\n",
    "                                    power=alpha)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid kernel type\")\n",
    "\n",
    "    gp.update_model_with_kernel(kernel)\n",
    "    current_kernel = gp.get_current_kernel()\n",
    "\n",
    "# Check if the kernel initialization was done correctly\n",
    "    print(\"Current Kernel:\", current_kernel)\n",
    "    # Calculate the utility using the expert data and the GP model\n",
    "    recorded_points = expert_data[[\"error_before_right_timing\", \"error_before_right_pitch\",\"practice_mode\", \"bpm\",\"utility\"]]\n",
    "    policy_diff = policy_diff_for_single_gp(gp, recorded_points)\n",
    "    return - mean(policy_diff)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_data[\"utility\"] = expert_data.apply(lambda row: error_diff_to_utility_for_opt(row[\"error_before_right_pitch\"],\n",
    "                                                                                row[\"error_after_right_pitch\"],\n",
    "                                                                                row[\"error_before_right_timing\"],\n",
    "                                                                                row[\"error_after_right_timing\"]),\n",
    "                                                axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -0.744143\n",
       "1    -0.721286\n",
       "2    -0.741024\n",
       "3    -0.731014\n",
       "4    -0.746581\n",
       "5    -0.670752\n",
       "6    -0.752638\n",
       "7    -0.752039\n",
       "8    -0.543385\n",
       "9    -0.749653\n",
       "10   -0.579054\n",
       "11   -0.674248\n",
       "12   -0.778682\n",
       "13   -0.738847\n",
       "14   -0.723135\n",
       "15   -0.730952\n",
       "16   -0.693829\n",
       "17   -0.700651\n",
       "18   -0.783743\n",
       "19   -0.727585\n",
       "20   -0.714198\n",
       "Name: utility, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data[\"utility\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Kernel: None\n",
      "0.952258926741977\n",
      "Current Kernel: None\n",
      "0.952258926741977\n",
      "Current Kernel: None\n",
      "0.952258926741977\n",
      "Current Kernel: None\n",
      "KeyboardInterrupt caught, calling on_optimization_end() to round things up\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     bounds_ \u001b[39m=\u001b[39m bounds\n\u001b[1;32m---> 20\u001b[0m bo \u001b[39m=\u001b[39m BayesianOptimization(f\u001b[39m=\u001b[39;49mobj_func,\n\u001b[0;32m     21\u001b[0m                           domain\u001b[39m=\u001b[39;49mbounds_,\n\u001b[0;32m     22\u001b[0m                           acquisition_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mEI\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     23\u001b[0m                           acquisition_jitter\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m,\n\u001b[0;32m     24\u001b[0m                           num_cores\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m \u001b[39m# Run the optimization\u001b[39;00m\n\u001b[0;32m     26\u001b[0m bo\u001b[39m.\u001b[39mrun_optimization(max_iter\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\GPyOpt\\methods\\bayesian_optimization.py:119\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[1;34m(self, f, domain, constraints, cost_withGradients, model_type, X, Y, initial_design_numdata, initial_design_type, acquisition_type, normalize_Y, exact_feval, acquisition_optimizer_type, model_update_interval, evaluator_type, batch_size, num_cores, verbosity, verbosity_model, maximize, de_duplication, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_design_type  \u001b[39m=\u001b[39m initial_design_type\n\u001b[0;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_design_numdata \u001b[39m=\u001b[39m initial_design_numdata\n\u001b[1;32m--> 119\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_design_chooser()\n\u001b[0;32m    121\u001b[0m \u001b[39m# --- CHOOSE the model type. If an instance of a GPyOpt model is passed (possibly user defined), it is used.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_type \u001b[39m=\u001b[39m model_type\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\GPyOpt\\methods\\bayesian_optimization.py:195\u001b[0m, in \u001b[0;36mBayesianOptimization._init_design_chooser\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m initial_design(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_design_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspace, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_design_numdata)\n\u001b[1;32m--> 195\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjective\u001b[39m.\u001b[39;49mevaluate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX)\n\u001b[0;32m    196\u001b[0m \u001b[39m# Case 2\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\GPyOpt\\core\\task\\objective.py:50\u001b[0m, in \u001b[0;36mSingleObjective.evaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39mPerforms the evaluation of the objective at x.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_procs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     f_evals, cost_evals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval_func(x)\n\u001b[0;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\GPyOpt\\core\\task\\objective.py:74\u001b[0m, in \u001b[0;36mSingleObjective._eval_func\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     73\u001b[0m     st_time    \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 74\u001b[0m     rlt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(np\u001b[39m.\u001b[39;49matleast_2d(x[i]))\n\u001b[0;32m     75\u001b[0m     f_evals     \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack([f_evals,rlt])\n\u001b[0;32m     76\u001b[0m     cost_evals \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mst_time]\n",
      "Cell \u001b[1;32mIn[35], line 15\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     12\u001b[0m best_gp_dict_policy \u001b[39m=\u001b[39m {}\n\u001b[0;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m kernel_type \u001b[39min\u001b[39;00m kernel_types:\n\u001b[1;32m---> 15\u001b[0m     obj_func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: objective_function(x, kernel_type)\n\u001b[0;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m kernel_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRatQuad\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     17\u001b[0m         bounds_ \u001b[39m=\u001b[39m rqk_bounds\n",
      "Cell \u001b[1;32mIn[34], line 35\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(x, kernel_type)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m# Calculate the utility using the expert data and the GP model\u001b[39;00m\n\u001b[0;32m     34\u001b[0m recorded_points \u001b[39m=\u001b[39m expert_data[[\u001b[39m\"\u001b[39m\u001b[39merror_before_right_timing\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39merror_before_right_pitch\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mpractice_mode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbpm\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mutility\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m---> 35\u001b[0m policy_diff \u001b[39m=\u001b[39m policy_diff_for_single_gp(gp, recorded_points)\n\u001b[0;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m mean(policy_diff)\n",
      "Cell \u001b[1;32mIn[31], line 21\u001b[0m, in \u001b[0;36mpolicy_diff_for_single_gp\u001b[1;34m(gauss_model, recorded_points)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m#add the data point to the gp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m gauss_model\u001b[39m.\u001b[39madd_data_point(complexity_level,tp, my_practice_mode, expert_opt_policy)\n\u001b[1;32m---> 21\u001b[0m gauss_model\u001b[39m.\u001b[39;49mupdate_model()\n\u001b[0;32m     23\u001b[0m \u001b[39m#calculate the policy diff for the current gp, for the current point\u001b[39;00m\n\u001b[0;32m     25\u001b[0m c\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\u001b[39m#what is c?\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 175\u001b[0m, in \u001b[0;36mGaussianProcess.update_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbayes_opt\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mkern\u001b[39m.\u001b[39mlengthscale\u001b[39m.\u001b[39mconstrain_bounded(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m,\n\u001b[0;32m    172\u001b[0m                                                            warning\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbayes_opt\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmax_iters \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m--> 175\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbayes_opt\u001b[39m.\u001b[39;49m_update_model()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\GPyOpt\\core\\bo.py:253\u001b[0m, in \u001b[0;36mBO._update_model\u001b[1;34m(self, normalization_type)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m         Y_inmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mupdateModel(X_inmodel, Y_inmodel, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    255\u001b[0m \u001b[39m# Save parameters of the model\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_model_parameter_values()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\GPyOpt\\models\\gpmodel.py:93\u001b[0m, in \u001b[0;36mGPModel.updateModel\u001b[1;34m(self, X_all, Y_all, X_new, Y_new)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39moptimize(optimizer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, max_iters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iters, messages\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, ipython_notebook\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49moptimize_restarts(num_restarts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_restarts, optimizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, max_iters \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iters, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\paramz\\model.py:172\u001b[0m, in \u001b[0;36mModel.optimize_restarts\u001b[1;34m(self, num_restarts, robust, verbose, parallel, num_processes, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    171\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandomize()\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimize(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\u001b[39m#pragma: no cover\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimization_runs\u001b[39m.\u001b[39mappend(jobs[i])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\GPy\\core\\gp.py:675\u001b[0m, in \u001b[0;36mGP.optimize\u001b[1;34m(self, optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference_method\u001b[39m.\u001b[39mon_optimization_start()\n\u001b[0;32m    674\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 675\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(GP, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39moptimize(optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    676\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    677\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKeyboardInterrupt caught, calling on_optimization_end() to round things up\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\paramz\\model.py:111\u001b[0m, in \u001b[0;36mModel.optimize\u001b[1;34m(self, optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m     opt \u001b[39m=\u001b[39m optimizer(max_iters\u001b[39m=\u001b[39mmax_iters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    110\u001b[0m \u001b[39mwith\u001b[39;00m VerboseOptimization(\u001b[39mself\u001b[39m, opt, maxiters\u001b[39m=\u001b[39mmax_iters, verbose\u001b[39m=\u001b[39mmessages, ipython_notebook\u001b[39m=\u001b[39mipython_notebook, clear_after_finish\u001b[39m=\u001b[39mclear_after_finish) \u001b[39mas\u001b[39;00m vo:\n\u001b[1;32m--> 111\u001b[0m     opt\u001b[39m.\u001b[39;49mrun(start, f_fp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_objective_grads, f\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_objective, fp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grads)\n\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_array \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mx_opt\n\u001b[0;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimization_runs\u001b[39m.\u001b[39mappend(opt)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\paramz\\optimization\\optimization.py:51\u001b[0m, in \u001b[0;36mOptimizer.run\u001b[1;34m(self, x_init, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, x_init, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     50\u001b[0m     start \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt(x_init, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     52\u001b[0m     end \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m     53\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(end \u001b[39m-\u001b[39m start)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\paramz\\optimization\\optimization.py:124\u001b[0m, in \u001b[0;36mopt_lbfgsb.opt\u001b[1;34m(self, x_init, f_fp, f, fp)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbfgs_factor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     opt_dict[\u001b[39m'\u001b[39m\u001b[39mfactr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbfgs_factor\n\u001b[1;32m--> 124\u001b[0m opt_result \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39mfmin_l_bfgs_b(f_fp, x_init, maxfun\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iters, maxiter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopt_dict)\n\u001b[0;32m    125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_opt \u001b[39m=\u001b[39m opt_result[\u001b[39m0\u001b[39m]\n\u001b[0;32m    126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_opt \u001b[39m=\u001b[39m f_fp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_opt)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:199\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    187\u001b[0m     disp \u001b[39m=\u001b[39m iprint\n\u001b[0;32m    188\u001b[0m opts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp,\n\u001b[0;32m    189\u001b[0m         \u001b[39m'\u001b[39m\u001b[39miprint\u001b[39m\u001b[39m'\u001b[39m: iprint,\n\u001b[0;32m    190\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxcor\u001b[39m\u001b[39m'\u001b[39m: m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m'\u001b[39m: callback,\n\u001b[0;32m    197\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxls\u001b[39m\u001b[39m'\u001b[39m: maxls}\n\u001b[1;32m--> 199\u001b[0m res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[39m=\u001b[39margs, jac\u001b[39m=\u001b[39mjac, bounds\u001b[39m=\u001b[39mbounds,\n\u001b[0;32m    200\u001b[0m                        \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n\u001b[0;32m    201\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mjac\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    202\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    203\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mfuncalls\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    204\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    205\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mwarnflag\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[0;32m    206\u001b[0m f \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    356\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    358\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    363\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39margs)\n\u001b[0;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\function_base.py:935\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(a, order, subok)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_copy_dispatcher)\n\u001b[0;32m    847\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy\u001b[39m(a, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mK\u001b[39m\u001b[39m'\u001b[39m, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    848\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[39m    Return an array copy of the given object.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    933\u001b[0m \n\u001b[0;32m    934\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mreturn\u001b[39;00m array(a, order\u001b[39m=\u001b[39;49morder, subok\u001b[39m=\u001b[39;49msubok, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from GPyOpt.methods import BayesianOptimization\n",
    "\n",
    "kernel_types = ['Matern52', 'linear', 'RatQuad']\n",
    "rqk_bounds = [{'name': 'variance', 'type': 'continuous', 'domain': (0.01, 1)},\n",
    "          {'name': 'lengthscale', 'type': 'continuous', 'domain': (0.1, 10)},\n",
    "          {'name': 'alpha', 'type': 'continuous', 'domain': (0.1, 10)}]\n",
    "\n",
    "bounds = [{'name': 'variance', 'type': 'continuous', 'domain': (0.01, 1)},\n",
    "          {'name': 'lengthscale', 'type': 'continuous', 'domain': (0.1, 10)}]\n",
    "\n",
    "best_gp_dict ={}\n",
    "best_gp_dict_policy = {}\n",
    "for kernel_type in kernel_types:\n",
    "\n",
    "    obj_func = lambda x: objective_function(x, kernel_type)\n",
    "    if kernel_type == 'RatQuad':\n",
    "        bounds_ = rqk_bounds\n",
    "    else:\n",
    "        bounds_ = bounds\n",
    "    bo = BayesianOptimization(f=obj_func,\n",
    "                              domain=bounds_,\n",
    "                              acquisition_type='EI',\n",
    "                              acquisition_jitter=0.05,\n",
    "                              num_cores=1)\n",
    "    # Run the optimization\n",
    "    bo.run_optimization(max_iter=5)\n",
    "    # Get the best set of hyperparameters\n",
    "    bo.plot_convergence()\n",
    "\n",
    "    best_hyperparameters = bo.x_opt\n",
    "    best_mean_policy_diff = bo.fx_opt\n",
    "    best_gp_dict[kernel_type] = best_hyperparameters\n",
    "    best_gp_dict_policy[kernel_type] = best_mean_policy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Matern52': array([0.79260453, 8.24210057]),\n",
       " 'linear': array([0.23349135, 7.13223911]),\n",
       " 'RatQuad': array([0.56805373, 3.71287811, 7.64203509])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Matern52': -0.952258926741977,\n",
       " 'linear': -0.952258926741977,\n",
       " 'RatQuad': -0.952258926741977}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gp_dict_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAFNCAYAAADRi2EuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABPI0lEQVR4nO3deZyT1d3//9eHRXYE2ReZcRlUBOuCoq0LbpVS9+5Fi60W7d1W22pbLe3d3gt39e52tz+/tVJttXXUitU6KioyFhzFFfcdVAQEFBdENtk+vz/OlRJCMpPJJLmuZN7PxyOPJNf6SSZz8sk55zrH3B0RERERKb0OcQcgIiIi0l4o8RIREREpEyVeIiIiImWixEtERESkTJR4iYiIiJSJEi8RERGRMlHi1Qpm9gcz+0nccRTCzMab2dK445DWMbNJZjYr7jikupmZm9meZT6nmdmfzex9M3s0z32uMbP/LtL555jZOcU4VjnE8TfKEsNZZvZAnDG0xMwWmdlxccfRHCVekeiPtd7MPjSzVWY2z8zOM7N/vUfufp67/1eex0r0H741lLSVh5nVRoVrp9Qyd69390+WOY6fmdnPynlOaRszu9vM/jPL8lPMbEX6ZypBDgeOB4a7+yGZKyvhSz5T0mOutGSzWinx2t5J7t4LqAEuBX4IXB1vSCIiLboWOMPMLGP5mUC9u2+OIaaW1ACL3H1t3IGIlJMSryzc/QN3bwC+AEw2s9GwfTW3mfU3szui2rH3zKzJzDqY2V+BEcDtZrbGzH4QbT8j+uX5gZndb2b7ps4XHff/mdmdUY3bI2a2R9r6fc3s3ug8b5nZj6LlHczsYjN71czeNbObzGyX5l6bmf3IzN6JauUmpS3vYma/NLPF0Tn+YGbdzKwHcBcwNHo9a8xsaFQ72D/ad6qZbTaz3tHz/zKz/2vuuGnnPdHMnkqrZdwvbd0iM7vIzJ6J3re/mVnXZl7b183sxeg9fMHMDoyW7xP90ltlZs+b2cn5vPcW/MbM3jaz1Wb2bNpnoaXXdUr0ulZHf58Jaa/puLTtfmZm10VP74/uV0Xv82Hpv6DN7Aoz+2XGa77NzL4XPR5qZn83s5Vm9rqZnZ/jfdopiu3b0fOOZvagmf17lm2zfs5z/Q0kNv8A+gFHpBaYWV/gROAvZnaImT0U/R2Xm9nlZrZTtgNZRq2IZdTimNneaeXRy2b2+VxBRZ/JhmjbhWb29Wj52cBVwGHRZ/0/MvbbB/hD2vpVaav7Zvt/bW1skT3M7NHo//Q2Sys/zezQqExaZWZPm9n4jPfktSiG1y10CWguZprbN23d16Iy7H0zu8fManIco9Xlj5lNI3w+Lo/iu7yl98zM+kV/v9UWmoP32CGYbdt2NbPrLHwXrTKzx8xsULTuq7atbH7NzM5N22+8mS01sx9YKGuXm9mpZjbRzF6J4vpR2vY/M7ObLXwffGhmT5jZx3LE1OrvyLJwd93CtEmLgOOyLF8MfCN6fA3w39HjnxP+yTpHtyMAy3Us4GtAL6AL8H/AU2nrrgHeBQ4BOgH1wI3Rul7AcuBCoGv0fFy07gLgYWB4dNwrgRtyvL7xwGbg19G2RwFrgb2i9b8BGoBdonPcDvw8bd+lGce7H/hM9HgW8CrwqbR1p+Vx3AOAt4FxQEdgcvTedUl7Hx8Fhkb7vwicl+P1fQ54EzgYMGBPwi/qzsBC4EfATsAxwIdpr7u59/4EYD7QJzrmPsCQPF7XIcAHhGaUDsAwYO9snw3gZ8B10eNawIFOaevPAh6IHh8JLGHb56wvsD56fzpEsf579Dp3B14DTsjxfo0G3o9e01TC56hjlu1yfs51S9YN+CNwVdrzc4nKGeAg4NDoM14b/S99J21bB/aMHs8BzsnxGewRfQa/Gh3rAOAdYFSOmO4Hfk8ou/YHVgLHZB43x747rG/h/7W1sc0hlBmjo33/nva/OCw6z8Tof+v46PmAaNvVbCtDhgD75vmamtv3FEJZtU8U/4+BeTn+RoWWP5l/22bfM+BG4KZou9HR+5X19RE+b7cD3Qnl+UFA72jdpwlJmxG+e9YBB0brxhO+m/6dUMZ8PfqcXB+9tn0J5dxu0fY/AzYBn422vwh4HegcrV9EVMbSiu/Isv6vxh1AUm7kTrweBqZGj69hW+L1n8BtqX+EfI6Vtr5P9E+0c9px0wvMicBL0eMvAU/mOM6LwLFpz4dEH8hOWbZNfbh7pC27CfhJ9M+wFtgjbd1hwOtp+2YmXv8F/C76Z10RfcAvJRSw6wm/vls67hXAf2Uc92XgqLT38Yy0df8L/CHHe3EPcEGW5UdE8XVIW3YD8LM83vtjgFcIX1jp+7f0uq4EfpPP54zWJV5G+CFwZPT868B90eNxwOKMc10C/LmZz+GF0fv9PlCXY5ucn3PdknUj9JlaBXSNnj8IfDfHtt8Bbk17nm/i9QWgKeNYVwI/zXKOXYEtQK+0ZT8Hrsk8bo4Yd1jfwv9r3rGlvc5L056PAjYSkoYfAn/N2P4ewo/DHtH7/BmgW0sxZ6xvbt+7gLPTnncgJCg16X8j2lb+ZP5tc75n0fuwiShpi9b9T67XR6hcmAfsl8dn9R9E5TXh+2U90Q8/QrLlRBUM0bL5wKnR458BD2e8T8uBI6Lni9iWeOX9HVnOm5oMWjYMeC/L8l8Qfp3MiqpOL851AAtNOZdG1Z2rCR8MgP5pm61Ie7wO6Bk93pVQm5RNDXBrVK27ivAh2wIMyrH9+759f4o3CLUlAwi/UuanHevuaHkucwn/MAcCzwL3En7JHAosdPfUr8PmjlsDXJhaF63fNYopJdf7kinX+zQUWOLuWzNe97CWzuHu9wGXA/8PeNvMpltoTm3pdTX3NyuYh5LjRkIyDvBlwi9+CO/l0Iz38kfk/ixA6BdUA8x09wU5tsn7cy7xcvcHCLUVp0bNb4cQag0ws5EWmoxXRGXQ/7B9+ZOvGmBcxudsEjA4y7ZDgffc/cO0ZZn/e4XIVSa0JraUJRmxdSa8LzXA5zKOdTihxnstIWE5D1huodlz73wCb2HfGuC3aed7j5BkZb5fxSx/mnvPBhB+WGe+R7n8lZCc3mhmy8zsf82sM4CZfcrMHo6aDVcREub0z9+77r4lerw+un8rbf16ti/7/xVTVLYvZfvvjfTX15rvyLJQ4tUMMzuY8KHf4SoVd//Q3S90992Bk4HvmdmxqdUZm3+ZUI18HLAzoWYDwj9VS5YQmo1yrfuUu/dJu3V19zdzbN/XQp+tlBHAMkJhvZ5Q5Z06zs7unvqgZ74eCL9s9gJOA+a6+wvR8SYSkjLyOO4SYFpG/N3d/YaW3pQc70W2/gfLgF1t+35JIwhV5i1y99+5+0GEX8Mjge/n+bpy9YVYSyg0U9K/FLK9z5luAD4b9f0YR2geSZ3z9Yz3spe7T2zmWL8H7gBOMLPDs23QwudckucvwFeAM4B73D315XUF8BKhZrM3ISnPVf409xldQvh/T/+c9XT3b2Q5zjJgFzPrlbYs7/898vt/SNea2FJ2zYhtE+H/ewmhxiv9WD3c/VIAd7/H3Y8n1KC8RGjmzSvmZvZdApybcc5u7j4v4xBtKX8y42vuPVtJaCXJfI9yva5N7v4f7j4K+Dihf+FXzKwLoZz6JTDI3fsAM8nv+y+Xf8UUle3DCZ+3TK39jiwLJV5ZmFlvMzuRULtwnbs/m2WbE81sTzMzQnv6FiBVq/IW2ydLvYCPCH0EuhN+bebrDmCImX3HQofKXmY2Llr3B2Ba9CWMmQ0ws1NaON5/WOhcfQThH2NG9Ivhj8BvzGxgdKxhZnZC2uvpZ2Y7pw7i7usI1b/fZFuiNY/wS25utE1Lx/0jcJ6ZjbOgh5l9OqOgztdVwEVmdlB0rD2j9+URwq/iH5hZZwsdZE8i/G2bZWYHR7F1JnwZbQC25vG6rga+ambHRp07h6X9qn0K+GIUy1hCP4WUlYTPUK5EG3d/klDwXkX4Yl0VrXoU+NDMfmjhooiOZjY6+vGQ7bWdSeiDcRZwPnCtme1Qm9jC51yS5y+EH3hfJ9RopvQi9C1aE30Wm0tGngJON7PuFsaNOjtt3R3ASDM7M/oMd47+T/bJPIi7LyGUCT+30PF6v+hY12Vum8NbwHDLcRFAFnnHluYMMxtlZt0Jzeo3RzUv1wEnmdkJ0f9SVwudwIeb2SALndd7EMr1NWxf9ueMuYV9/wBcYtGFV2a2s5l9LvMYbSx/Mr+bcr5n0ftwC/Cz6LMwitDUmpWZHW1mY8ysI+Gztil6bTsR+letBDab2aeAtg6Rc5CZnW5hmJTvEN7Lh7NsV8h3ZMkp8dre7Wb2ISFLnkroiP7VHNvWAbMJ/zgPAb93939G634O/NhC9eZFhMLwDcIvvRfI/gHJKqqmP56QLKwAFgBHR6t/S+hgOSuK+2FCLUguKwj9eZYRmqjOc/eXonU/JDQpPWyhKWI2oUaLaJsbgNei15Sq0p1LqJp/NO15L7ZdndfScR8nfEFcHsW1kJAItJq7zwCmEZpWPiT0IdjF3TcS3rtPERKW3wNfSXvdzelNKODeJ/z93iU0vbX0uh4lfG5+Q0hW5hKqvCH0qdsjOuZ/RPGmXsO66DU8GL3Ph+aI63rCl2v6vlsIifT+hI6mqeRs58ydzWwE4QKPr7j7Gne/Hng8ijdTc59zSRh3X0RIdnoQyoaUiwg17x8SPtN/a+YwvyH0dXqLkLylmrNT5dEngS8SypEVwGWEL9ZsvkSo4V8G3ErobzU7z5dzH/A8sMLM3mlp4wJig9A8dk20bVfCj5BU0ngKoWZwJeE74fuE78wOwPeic7xH6GKRSmRbijnnvu5+axTvjVGZ8hyh3Mqm0PLnt4Qa8/fN7Hd5vGffIjTxrYjepz/niAdCzejNhKTrxei8f43OcT6hT/H7hM9hQ66D5Ok2QpPt+4QhU053901Ztmvtd2RZpK6OEhEREUk0C4M77+nuZ8QdS6FU4yUiIiJSJkq8RKTdMLNdLAwWuSC675tju8vM7Lno9oW05btZGLRzoYUBHPPtfyQiApQw8TKzP1kYhfa5tGV5FXoiIiVyMdDo7nVAY/R8O2b2acIwKfsT+oNcZNGsDIT+L79x9z0J/UvOztxfRErH3X9Wyc2MUNoar2uACRnLWiz0RERK6BS2Xe13LXBqlm1GAfe7+2YP4y49A0yIruw8htCBuLn9RURyKlni5e73s+PAo/kUeiIipTLI3ZdHj1eQfSDFpwmJVncL85EeTRg3qB+wyrdNOL2Utg8GKiLtTKcyny+fQm8H/fv399ra2rxOsHbtWnr06NHyhmWSpHiSFAskK54kxQLJiieOWObPn/+Ouzc3c0JOZjab7KOVT01/4u5uZjtc1u3us6Lxz+YRhhJ4iDB+WWtimAJMAejWrdtBu+66awt7bLN161Y6dIi3+61iSEYMcZ9fMRQewyuvvJKzDCt34vUvuQq9lPSCa9CgQfzyl7/M67hr1qyhZ89cs8qUX5LiSVIskKx4khQLJCueOGI5+uijm5uapFnuflyudWb2lpkNcfflZjaEMEl7tmNMI4yphpldT5iz812gj5l1imq9hpNjFHZ3nw5MBxg7dqw//vjjecc/Z84cxo8fn/f2paAYkhFD3OdXDIXHYGY5y7ByJ155FXqwY8GV7wtOwh8oXZLiSVIskKx4khQLJCueJMVSBA2E0bcvje5vy9wgGnm7j7u/G422vh8wK/qx+E/CbAM35tpfRKQ55a67SxV6oEJLRMrvUuB4M1tAGP3/UgAzG2tmV0XbdAaazOwFwo+/M9L6df2QMF/lQkKfr6vLGr2IVLyS1XiZ2Q3AeKC/mS0Ffkoo5G4ys7MJU7B8vlTnFxHJ5O7vAjtM8h1NX3VO9HgD4crGbPu/BhxSyhhFpLqVLPFy9y/lWLVDoSciIiLSHmjkehEREZEyUeIlIiIiUiZKvERERETKRImXSDHU10NtLXToEO7r6+OOSEREEii2AVRFqkZ9PUyZAuvWhedvvBGeA0yaFF9cIiKSOKrxEmmrqVO3JV0p69aF5SIiImmUeIm01eLFrVsuIiLtlhIvkbYaMaJ1y0VEpN1S4iXSVtOmQefO2y/r3j0sFxERSaPES6StJk2C3Xbb9nzYMJg+XR3rRURkB0q8RNpq5UpYuBA+/vHw/LrrlHSJiEhWSrxE2mrmTNi6Fc4/Pzx/44144xERkcRS4iXSVg0NoXnxlFPC80WLYg1HRESSS4mXSFts2AD33AMnnwxdu8KQIarxEhGRnJR4ibTFfffB2rUh8YIwXZASLxERyUGJl0hbNDRAz55w9NHheU2NmhpFRCQnJV4ihdq6FW6/HSZMgC5dwrLaWliyJKwTERHJoMRLpFDz58OyZduaGSHUeG3aBMuXxxeXiIgklhIvkUI1NECHDjBx4rZlNTXhXs2NIiKShRIvkUI1NMDhh0O/ftuW1daGe3WwFxGRLJR4iRRi0SJ45pltY3elpCbGVo2XiIhkocRLpBC33x7uTzpp++U9esCAAarxEhGRrJR4iRTitttgn32grm7HdTU1SrxERCQrJV4irbVqFcydu/3VjOk0lpeIiOSgxEukte6+GzZvzp141dbC4sXgXtawREQk+ZR4ibRWQwMMHAjjxmVfX1MD69fDypXljUtERBJPiZdIa2zaBDNnwoknQseO2bfRWF4iIpKDEi+R1rj/fvjgg9zNjKCxvEREJCclXiKt0dAAXbvCccfl3kY1XiIikoMSL5F8uYfE6/jjw3hduey8M/TpoxovERHZgRIvkXw991yoxWqumTFFY3mJiEgWSrxE8nXbbeH+xBNb3lZjeYmISBZKvETy1dAQhpAYPLjlbWtrQ42XxvISEZE0SrxE8rFsGTz22I6TYudSUwMffgjvv1/auEREpKIo8RLJxx13hPt8+nfBtisb1c9LRETSKPESycdtt8Huu8OoUfltr7G8REQkCyVeIi1ZswYaG0Ntl1l++2gsLxERyUKJl0hL7r0XPvoo/2ZGgH79wlhfqvESEZE0SrxEWtLQAH37wuGH57+PmcbyEhGRHSjxEmnOli2hY/3EidC5c+v21VheIiKSQYmXSHMeegjeead1zYwpqbG8REREIkq8RJrT0BBquiZMaP2+NTXw3nthPC8RERGUeIk0r6EBjj4aevdu/b4ayytxzGwXM7vXzBZE931zbHeZmT0X3b6QtrzezF6Olv/JzFrZ/iwi7Z0SL5FcXn453AppZgSN5ZVMFwON7l4HNEbPt2NmnwYOBPYHxgEXmVkq864H9gbGAN2Ac8oQs4hUESVeIrk0NIT7k04qbH+N5ZVEpwDXRo+vBU7Nss0o4H533+zua4FngAkA7j7TI8CjwPDShywi1SSWxMvMvmtmz0fV9TeYWdc44hBpVkMD7L8/jBhR2P6DBkGXLqrxSpZB7r48erwCGJRlm6eBCWbW3cz6A0cDu6ZvEDUxngncXcpgRaT6dCr3Cc1sGHA+MMrd15vZTcAXgWvKHYtITitXwrx58JOfFH6MDh1C0qbEq6zMbDYwOMuqqelP3N3NzDM3cvdZZnYwMA9YCTwEbMnY7PeEWrGmHDFMAaYADBo0iDlz5uQd/5o1a1q1fSkohmTEEPf5FUNpYih74pV23m5mtgnoDiyLKQ6R7GbOhK1bC+/flaKxvMrO3Y/Ltc7M3jKzIe6+3MyGAG/nOMY0YFq0z/XAK2nH+CkwADi3mRimA9MBxo4d6+PHj887/jlz5tCa7UtBMSQjhrjPrxhKE0PZmxrd/U3gl8BiYDnwgbvPKnccIs267TYYNgwOOKBtx9FYXknTAEyOHk8GbsvcwMw6mlm/6PF+wH7ArOj5OcAJwJfcfWtZIhaRqhJHU2NfQgfX3YBVwAwzO8Pdr8vYrqCq+iRUSaZLUjxJigWSFU96LB02buQTd93Fik9+kgVz57bpuDVbt7LbW29x/z33sLVLl4LiiVuSYimCS4GbzOxs4A3g8wBmNhY4z93PAToDTRYmRF8NnOHum6P9/xDt91C0/hZ3/8/yvgQRqWRxNDUeB7zu7isBzOwW4OPAdolXoVX1SaiSTJekeJIUCyQrnu1imTkTNmxg2L/9G8PaGt+SJfCnP3FkbS3stVdh8cQsSbG0lbu/CxybZfnjRENDuPsGwpWN2faPq3uGiFSJOK5qXAwcGl0xZIRC8MUY4hDJrqEBevaEYiQbGstLRETSxNHH6xHgZuAJ4NkohunljkMkq61b4fbbwxRBrWgazEljeYmISJpYqs3d/afAT+M4t0iz5s+HZcvafjVjytCh0KmTarxERATQyPUi22togI4dYeLE4hyvUycYPlyJl4iIAEq8RLbX0ACHHw79+hXvmBrLS0REIkq8RFIWLYJnnileM2OKxvISEZGIEi+RlLZOip1LTQ28+SZs3Fjc44qISMVR4iWS0tAA++wDdXXFPW5NDbjD0qXFPa6IiFQcJV4iQKc1a2DuXDjllOIfXGN5iYhIRImX5K++PiQRHTqE+/r6uCMqml0efRQ2by5+/y7QWF4iIvIvSrwkP/X1MGVKqLVxD/dTplR+8hUlk/v813+FhHLhwuKfY9ddwUw1XiIiosRL8jR1Kqxbt/2ydevC8kqVlkwahFHrzzuv+MnkTjuFgVRV4yUi0u4p8ZL8LF7cuuWVoJzJZE2NarxERESJl+RpxIjWLa8E5UwmNZaXiIigxEvyNW0adO68/bLu3cPySlXOZLKmBpYsgS1bin9sERGpGEq8JD+TJoVO4jvttG3ZJZeE5ZVq2jTo1m37ZaVKJmtrw1WTy5YV/9giIlIxlHhJflauhNdfD/2f3nsPunSBt9+OO6q2mTQJvvpVABxCrdT06aVJJlNDSqi5UUSkXVPiJfm5554wjMSnPgV9+4aBRq+/vvKnwfnoI+jTh7mzZ4erDktVg6exvEREBCVekq+77oIBA+Cgg8Lzs86Cd9+FO++MNaw2cYfZs+Hoo6Fjx9KeSzVeIiKCEi/Jx5YtocbrhBPCIKMAxx8PgwfDNdfEGlqbvPZaSISOO6705+rWDQYOVI2XiEg7p8RLWvb446F2a+LEbcs6dYIzz4SZMyu3r9fs2eH+2GPLcz6N5SUi0u4p8ZKW3XVXqOn65Ce3Xz55crhS7/rr44mrrRobYfhwGDmyPOfTWF4iIu2eEi9p2V13wSGHQL9+2y/fd18YOxauvTaeuNpi61a4775Q22VWnnOmary2bi3P+UREJHGUeEnzVq6Exx4LVzNmM3kyPPUUPP10WcNqs6efDs2n5ejflVJbG66irNSmWRERaTMlXpnq68MXZIcO4b7QCZOj4xx1zDFtO07cZs3aNoxENl/6UhjRvtJqvcrdvwt0ZaOIiNAp7gASpb4epkzZNnHyG2/AOeeEuftOOSUkGJm3Tp22PU4NSZB2HEsdZ8qUsK7SRnrPHEYiU79+cNJJcN11cNllO04rlFSNjTBqFAwZUr5zpo/lNW5c+c4rIiKJoRqvdFOnbku6UjZsgB/9KPRnGjkSdtstdMgeNAh22QV69w5DBXTqFGrJunQJV/tlHmfdunD8SpJtGIlszjorNEnefXfZQmuTjz6C++8vbzMjqMZLRERU47WdxYuzLzcLV+5t3gybNu14y1x+2WWtO35SPf44vPNO7mbGlAkTQq3YNdeE2q+ke/hhWL++vM2MEJL0vn01lpeISDumxCvdiBHZayNGjIAvfjH/49x4Y+7jVJK77gpJZ+YwEpk6d4YzzoDLLw8d1jOvfkya2bNDs/BRR5X/3BrLS0SkXVNTY7pp03acOqZ797C8tcfp3r3tx4lbahiJ/v1b3nby5FDbd8MNpY+rrRob4eCDYeedy39ujeUlItKuKfFKd+KJ4b5Xr1DTU1MD06e3vkP8pElhv112Cc+HDSvsOHFqaRiJTB/7GOy/f/KvbvzgA3j00fL370qpqQlNje7xnF9ERGKlxCvd7beHDuV33x0GuVy0qPBkadIkuPnm8Piaayor6YKWh5HIZvLk0C/s+edLF1dbzZ0b/sbl7t+VUlsLa9fCe+/Fc34REYmVEq90M2aE2qlDDy3O8erqwv2CBcU5XjmlhpEYOzb/fb785XB1Z5JrvRobw1Wohx0Wz/l1ZaOISLumxCtl9eowdMJnP9v80AmtMXQoW7p0gVdeKc7xymXr1vyGkcg0cGCYSPuvfw1XeibR7NlwxBFh2I84pI/lJSIi7Y4Sr5Tbbw/jO33uc8U7ZocOrB82rPJqvPIdRiKbyZNhxQq4997ix9VWy5fDCy/E178LQlMjqMZLRKSdUuKVkmpmLHIT1Prhwysv8cp3GIlsTjwxDCdxzTVFD6vNGhvDfVz9uyCM49Wzp2q8RETaKSVeEJoZ774bPvOZ4jUzRtYNHw6vvZbcprdsWjOMRKaddgrzN952G7z/fvFja4vGxnCl6f77xxdD6mpZ1XiJiLRLSrwA7ryz+M2MkfXDh4ekq1JqON55Jwy3UEgzY8pZZ4X3829/K1pYbeYe+ncdc0zRk+tW01heIiLtlhIvCM2MQ4fCxz9e9EOvHz48PKiUDvaFDCOR6cADw9yWSbq6ccECWLo03v5dKamxvEREpN1R4rVmTWhaK0EzI0RNjVA5/bxmzgxNjK0ZRiKTWaj1evhhePnlooXWJrNnh/s4+3el1NbCqlWhiVtERNoVJV533AEbNpSkmRFgU58+YXLkSki8Ch1GIptJk8IxklLr1dgYapr22CPuSDSWl4hIO6bEa8YMGDIEPvGJ0hzfDEaOrIymxrYMI5FpyBCYMAH+8pcwUnyctmyB++4LtV1m8cYCGstLRKQda9+J15o1oWmtRM2M/1JXVxk1XqlhJE44oTjHmzwZ3nwzJD1xevLJ0LSXhP5doLG8RETasfadeN15Z0mbGf+lri58yW7YUNrztNVdd8HBBxc2jEQ2J58MffrEP6ZXqn/XMcfEG0fKwIHQtatqvGJgZruY2b1mtiC675tju8vM7Lno9oUs639nZmtKH7GIVJv2nXjNmAGDB5eumTFl5MhwpeBrr5X2PG2RGkZi4sTiHbNrV/jiF+HWW+GDD4p33NZqbIQxY2DQoPhiSGcGI0aoxiseFwON7l4HNEbPt2NmnwYOBPYHxgEXmVnvtPVjgawJm4hIS1pMvMxsuJldZGa3mdljZna/mf3ezD5tZpWbuK1du62ZsWPH0p6rEibLLsYwEtmcdRasXx+S3Dhs2AAPPJCMqxnTaSyvuJwCpK74uBY4Ncs2o4D73X2zu68FngEmAJhZR+AXwA9KH6qIVKNmEycz+zPwJ2AjcBnwJeDfgNmEgugBMzuy1EGWxJ13hoSg1M2MsC3xSnIH+7vuavswEtkccgjstVd8VzfOmxeSr6T070rRWF5xGeTuy6PHK4Bs1aBPAxPMrLuZ9QeOBnaN1n0LaEg7hohIq3RqYf2v3P25LMufA24xs52AEcUPqwxmzAhNT4cfXvpz9e0bkpqk1ngVcxiJTKkxvS65BBYuhD33LO7xWzJ7NnTqBEcm7PdBbS2sXAnr1kH37nFHU1XMbDYwOMuqqelP3N3NzDM3cvdZZnYwMA9YCTwEbDGzocDngPF5xDAFmAIwaNAg5syZk3f8a9asadX2paAYkhFD3OdXDKWJodnEK0fSlb5+I7CwtSc1sz7AVcBowIGvuftDrT1OwdauDTVeZ51V+mbGlCRf2Th/fkgCit3MmHLGGfCjH4WhJf7zP0tzjlwaG2HcOOjVq7znbUn6WF777BNvLFXG3XNWb5rZW2Y2xN2Xm9kQ4O0cx5gGTIv2uR54BTgA2BNYaGFYku5mttDdd/g14e7TgekAY8eO9fHjx+cd/5w5c2jN9qWgGJIRQ9znVwyliaGlpsbVLdw+NLNC2s9+C9zt7nsDHwNeLCT4gs2cWb5mxpQkj+VV7GEkMg0fDscfH5obt24tzTmyef/9MDZZ0vp3gQZRjU8DMDl6PBm4LXMDM+toZv2ix/sB+wGz3P1Odx/s7rXuXgusy5Z0iYg0p6V2pVfdvXczt17A2tac0Mx2Bo4EroZQa+buqwqKvlAzZoRL+svZ/FRXB8uWhbHDkmbmzOIOI5HN5MmweDHMnVu6c2SaMyckeknr3wUayys+lwLHm9kC4LjoOWY21syuirbpDDSZ2QuEWqsz3H1zLNGKSNVpKfH6TB7HyGebdLsR+k382cyeNLOrzKxHK49RuHXrQjPj6aeXr5kRtnWwX9jqltnSSg0jUapmxpRTTw1TJ5VzTK/GxtB/aty48p0zX0OGhL5n6mBfVu7+rrsf6+517n6cu78XLX/c3c+JHm9w91HR7VB3fyrHsXqWMXQRqRIt9fFqceCpfLbJcs4DgW+7+yNm9lvCWDo/Sd+o0M6pLXWA6z93LqPXreOpujpWlaGzXiqenqtXMxZ4/h//YOWqVSU/b3OxpBs4ezaj3Jk/cCAflvj9GHnEEQy66SbmffGLbOnWreQdJg9paGD9mDE8O29ei9vG0Xlz3IABrH70UV7Mct4kdCZNSVIsIiKVrqWrGnMys2fdfUwBuy4Flrr7I9Hzm8kyiGGhnVNb7AD3hz/AgAHsf/75ocahxP4Vz9ix8PWvs+9OO0FMnQSzvjdXXw39+nHQueeWvgawc2e4806OeOstOOus0naYXLoUliyh+wUX5HWOWDpv7r033TZsYFCW8yahM2lKkmIREal0zWYeZnZ6rlVkv1y7Re6+wsyWmNle7v4ycCzwQiHHarX16+GOO8JVdmVIurbTsycMHZqsDvbpw0iUo9n14x8Pw0lce224orSUGhvDfRL7d6XU1ISBa0VEpN1oKfv4G1BPGPIhU9c2nPfbQH00DthrwFfbcKz83XVXGEqinFczpkvakBKlHkYik1noZP+Tn8Drr5f2XI2N4WKBMYVUypZJbS0sXw4ffQRdusQdjYiIlEFLidczwC+zjedlZgVXJUSdVYs8RHoeZswIX8ZHHVX2UwMh8frHP+I5dzalHkYimzPPDInXAQdw1OrVYc7CadNg0qTincM9DJx67LHFHxC2mGpqQqxLlpR/YFkREYlFS99K3wFW51h3WnFDKbH16+H228PVjOVuZkwZOTJcRRhT5/od3HVXGEZiwIDynfOBB0Iy9MEHmHsYTmHKFKivL945Xnop1CQlcfyudBrLS0Sk3Wk28XL3JndfnGPd46UJqUTuvjveZkZI1mTZ774LjzxSvmbGlKlTdxxEdd26sLxYZs8O90nu3wUay0tEpB1qdTuMmT1RikBKLtXMGOfVWSNHhvskdLCfNSs0c5U78VqcNY/PvbwQjY2w++6w227FO2YpDB8eav80lpeISLtRSAcYK3oUpZZqZjzttPiaGSEkA2bJqPG66y7o1y8Mc1FOI3LMqZ5reWtt3gz//GfymxkhDK8xdKhqvERE2pFCEq87ix5Fqd1zT5iqJ85mRoCuXUOCEXeN19atoem1XMNIpJs2LYwmn65z57C8GObPh9Wrk9/MmFJbq8RLRKQdaXXi5e4/LkUgJTVjRqjdOfrouCMJzY1x13iVexiJdJMmwfTpUFODm0GPHrBpU/ESwFT/riT8rfNRU6OmRhGRdiSvxMvMTjezBWb2gZmtNrMPzSzX1Y7JsmFDMpoZU1JjeXm2odHKJI5hJNJNmgSLFjH3vvtCJ//DD4evfjXMGdlWjY2w//7lvVKzLWprwyj7mzUHs4hIe5Bvjdf/Aie7+87u3tvde7l771IGVjT33AMffgif/WzckQR1dfDBB6HGKS533RX6diUhOenSBW65BQYPhlNOCUlIodatgwcfrIz+XSk1NbBlC7z5ZtyRiIhIGeSbeL3l7i+WNJJSmTEDdtkFjjkm7kiC1JWNcTU3xjWMRHMGDAi1kmvXhuRr7drCjvPgg7BxY+X07wKN5dUMM7vFzD5tZgkeBVdEpHXyLdAeN7O/mdmXombH05uZxzE5NmyAhgY49dTQgTsJ4h7LK65hJFoyejTceCM89VSYVihzrK98zJ4d/s5HHFH08EpGY3k15/fAl4EFZnapme0Vd0AiIm2Vb+LVG1gHfBI4KbqdWKqgiubee0MzY9xXM6arrQ19zeK6sjE1jMTBB8dz/uZMnAi/+AX8/e/w05+2fv/GRjjssNBhv1KkhtFQB/sduPtsd58EHAgsAmab2Twz+6qZJeSXlIhI6+TV29zdyzOJdbHNmAF9+yarz0/nzmFgzzhqvOIcRiJf3/0uvPAC/Pd/wz77wJe/nN9+774LTzwBP/tZScMruq5dQ/821XhlZWb9gDOAM4EngXrgcGAyMD6+yERECtNsjZeZTWnpAPlsE4uPPoLbbktWM2NKXV0sNV69FiyIbxiJfJnB738PRx4JX/ta6I+Wj3/+MzShVlL/rpSaGiVeWZjZrUAT0B04yd1Pdve/ufu3gZ7xRiciUpiWarwuNrN3mllvwAXA9OKFVCT33hsG0kxSM2PKyJEwZ05IFKx8EwHs8sgj8Q4jka+ddgrNjePGhc72jz0Gu+7a/D6NjdCzZzKbUFtSUxNq6yTT79z9n9lWuHuZp1wQESmOlvp4zWVbn65stxOBe0sZYMFmzIA+fZLVzJhSVxeGPli2rDznq6+H2lpq//znUPs3a1Z5ztsW/fuHKx3Xr4eTT275SsfZs8M8nEmr3cxHbW2Yq7KQCwqqWK6kS0SkkjVb49Vc3y4z28ndNxY/pCJINTOedlqoPUma9Mmyhw0r7bnq62HKFFi3LkyyuXFjeA5hINMkGzUqXOl44olw5plw881hUulMb7wBCxfCN79Z/hiLoaYm/F1WrAhzN4qISNXKd+T6OWZWm/b8YOCxUgXVZrNnh0FKk9jMCOUdUmLq1FC7lm7durC8EnzqU/DrX8Ott8JPfpJ9m8bGcF+J/btAY3mJiLQj+Q4n8XPgbjP7NzObRujTldwrHVPNjEn9It511zBiezk62C9e3LrlSXT++aGW7n/+J9TgZWpshEGDYN99yx9bMWgsr6zMrDGfZSIilSTf4STuMbPzCP253gEOcPcVJY2sQLZpU2hmPOWUZDYzQmgu23PP8tR4jRiR/Qs9NX5UJTCDyy8PierZZ8Puu4fxuiBcoNDYGPrylfFChaJK1XhpLC8ANmzYANAR6G9mfQkX8UAYT7DEbfMiIqWVV+JlZj8BPg8cCewHzDGzC939zlIGV4i+8+fDqlXJbWZMqauDl18u/XmmTYOvfz10Uk/p3j0srySdO4c+XuPGhSFCHnssJI/PPw9vvZXMiyjy1bNnGNRWNV4AXHnllQCjoqfz2ZZ4rQYujyOmcvjHk2/yi3te5s1V6xn28H18/4S9OPWA/PPM1P7LVq1naJ9urd5fMSQnhraeXzEkK4ZM+TY19gMOcfeH3P1K4ATgO206c7FFV+6NueSSUPPxTnOjYCRAXR28+mqYILmUJk2Cc88FwCHUrkyfnvyO9dn06wd33BEunjj5ZFizJvTng+Q2K+erpkY1XpELLrgA4FngInff3d13i24fc/eqTLz+8eSbXHLLs7y5KvxAenPVei655Vn+8WR+k6en7+8F7K8YkhNDW8+vGJIVQzbm7m06QDmMHTvWH3/88dwbpF259y/duyciwZgzZw7jx4/fccVVV4WaqNdeCyPZl9L3vge//z1zGxo46pOfLO25WiHne9OSWbNCp/v99w+j3G/YEBKXadMK/nsXHEuxnH46vPRSeD1JiCdNHLGY2XzgMuBud//QzH5MmDrov929ogY9a7H8Aj5x6X3/KtzT7dSxAweM6NPiOZ5cvIqNW3YcjiTf/YtxDMWQjP0VQ+ljGNanGw9efEyz+5rZ/FzjDeZb45VslXjlXurKxnJ0sG9qgnHj8KT2eWutT34yJFhPPBGSLgjNdFOmZO98Xwlqa8NrqIAfQmX0kyjpOhw4DrgauCLmmEpiWZakC8ha6Ldmu3z3L8YxFEMy9lcMpY8h1/9rvvLq45V4lXjlXmosrwULSjuS/Jo18OSTcPHFpTtHHObO3XFZKtmuxGbUmpoQ/zvvwIABcUeTFKl2+E8D0939TjP77zgDKpWhfbplrfEa1qcbfzv3sBb3z1Vjlu/+xTiGYkjG/oqh9DEM7dMtr/PnUh01Xrmu0EvylXuDB4dO1aW+svGhh0I/siOOKO15ym3JkuzLk5xsN0djeWXzppldCXwBmGlmXaiWMivD90/Yi26dt5+4vlvnjnz/hL3Ksr9iSE4M1fAaFEPzCqrxMrN/A94F/u7um9sUQTFMm5a9j1eSr9wzC0NKlLqpsakpDF9x2GHVNR9gNQyTkS59LK+xmoYw8nlgAvBLd19lZkOA78ccU0mkrpL619VTrbz6Kn3/Qq/eUgzJiKGt51cMyYohK3dv9Q34JvD/AQ2F7N/a20EHHeQtuu4695oa32rmXlMTnifAP//5z9wrP/959z32KG0A48e7H3hgy7HEoE3xXHede/fu7qFXVLh1717w3z329+a998Jr+OUvkxFPmjhiAR4PdxwOfDV6PADYzctQ5hTzllf5lSYJf3vFkIwY4j6/Yig8hlQZlu1WULW9u/8/d/+2u5/ctrSviCZNgkWLmHvffeGy/Ero51NXF2LdWKIpLzduhIcfrr5mRgh/3+nTQxOdWWUPkwFhpoXevdXUmMbMfgr8ELgkWtQZuC6+iERE2q7ZpkYz+10ex1jt7j8uUjzty8iRof/V66/DXm1rM85q/vxw1V81Jl4QkqxKTbQypZJHjeWV7jTgAOAJAHdfZma94g1JRKRtWurjdQrw7y1sczGgxKsQ6ZNllyLxamoK94cfXvxjS/HV1KjGa3sb3d3NzAHMrEfcAYmItFVLiddv3P3a5jaI5lKTQpR6LK+mppDQDRpUmuNLcdXWbkuWBeCm6KrGPmb2deBrwB9jjklEpE2aTbzc/f9aOkA+20gO/fpB376lGVJi61Z44AH47GeLf2wpjZoa+OCDMNeo4O6/NLPjCXM07gX8u7vfG3NYIiJtku8k2QOArwO16fu4+9dKE1Y7YRZqvUqReD33XPgCr9b+XdVIY3ntIEq07jWz/oQhbEREKlq+VzXeBuwMzAbuTLtJW40cWZqmxlSTlRKvypE+llc79vDDDwPsZWa3mNkBZvYc8BzwlplNiDc6EZG2yXcA1e7u/sOSRtJe1dXBddfB+vXQrW3TEGynqQmGDdv2ZS7Jl6rxWrQI9tsv1lDi9K1vfQtgOXADcB/wKXd/2Mz2jpbdHWN4IiJtkm+N1x1mNrGkkbRXqQ72CxcW75juIfE64ojQnCmVYcCAkHy38xqvzZs3QximZgawwt0fBnD3l2INTESkCPJNvC4gJF/rzWy1mX1oZqtLGVi7kT5ZdrG8/josW6ZmxkqjsbwA6NBhu2Ipc4ZaL2MoIiJFl1dTo7tr0MJSSR/Lq1jUv6tyaSwvnn76aYADzOxDoFvajzwDusYWmIhIETRb42Vmg1s6QD7bSDN694aBA4vbwb6pKQxTse++xTumlEdtbbtPvLZs2QLwpLv3cvdO7t47uvVy985tObaZ7WJm95rZgug+6ziEZnaZmT0X3b6QttzMbJqZvWJmL5rZ+W2JR0Tan5aaGmfmcYx8tpHmjBxZ/Bqvww+HDgVNxSlxqqmBd96hw/rMFjYpkouBRnevAxqj59sxs08DBwL7A+OAi8ysd7T6LGBXYG933we4sQwxi0gVaemb+WPpfboybh9GTQEaFr2t6uqKV+O1YkU4lpoZK9PSpQAcMXFiqP2qr483nupzCpCajeNa4NQs24wC7nf3ze6+FngGSA1j8Q3gP919K4C7v13acEWk2jSbeLl7x7Qq/t4Zt17RbVi5gq1aI0fCW2/B6iJcr/DAA+FeiVflqa+Hq68GQmcm3ngDpkxR8lVcg9x9efR4Bdl/OD4NTDCz7tHArUcTarkA9gC+YGaPm9ldZlZX+pBFpJrkO3L92e5+ddrzjsCP3f0/ShZZe5I+pMSBB7btWE1NYUiCth5Hym/qVPjoo+2XrVsXlk+aFE9MFcjMZgPZ+p5OTX+SPgF3xvJZZnYwMA9YCTwEbIlWdwE2uPtYMzsd+BOww68cM5sCTAEYNGgQc+bMyTv+NWvWtGr7UlAMyYgh7vMrhtLEkO8Aqsea2WeAs4F+wJ+BuUWJQLafLLsYidehh8JOO7U9LimvxYtbt1yycvfjcq0zs7fMbIi7LzezIUDWpkJ3nwZMi/a5Hkj1BVgK3BI9vpVQFmbbfzowHWDs2LE+fvz4vOOfM2cOrdm+FBRDMmKI+/yKoTQx5NX72t2/TOgP8SxhqqDvuPtFRYlAYM89w31bO9ivXg1PP61mxko1YkTrlkshGoDJ0ePJhOnQtmNmHc2sX/R4P2A/YFa0+h+EpkeAo9iWkImI5CWvxCvqx3AB8HfgDeBMM+velhNHhduTZnZHW45TFbp3h+HD2554zZsHW7cq8apU06aFz0K67t3DcimWS4HjzWwBcFz0HDMba2ZXRdt0BprM7AVCrdUZ7r45bf/PmNmzwM+Bc8oavYhUvHybGm8HvunujWZmwPeAx4C2DBR1AfAi0LulDduFYkyW3dQEHTuGpkapPKl+XN/+Nrz/fkjGL71U/buKyN3fBY7NsvxxoiTK3TcQrmzMtv8q4NMlDFFEqly+Az0d4u6NEDqkuvuvgNMKPamZDScUXle1tG27UVfX9hqvpqbQR6xnz+LEJOU3aRLcGA0N9Ze/KOkSEakyLY1cfziAu+8wzoG7v2Jmvc1sdAHn/T/gB8DWAvatTnV18N578O67he3/0Ufw6KNw5JHFjUvKb8yYcP/cc/HGISIiRddSU+NnzOx/gbuB+YRLq7sCexI6mNYAF7bmhGZ2IvC2u883s/HNbFfQ5dhJuOw0Xb7x9PvoI8YAT/ztb6welbWVo1k7P/ssB3z0Ec/26cO7Oc5Xqe9NOSQpFtz5eK9evDNrFq+kkrAYJeq9ERGpcM0mXu7+XTPbBfgM8DlgCLCe0DfrSnd/oIBzfgI42cwmEpK43mZ2nbufkXHugi7HTsJlp+nyjmfwYJg6lQN79YJC4p83D4Ax3/gG9OvXtljKJEnxJCkWgFW77cbQd99laAJiStp7IyJSyVrsXO/u7wF/jG5t5u6XAJcARDVeF2UmXe3S7ruHuRUL7WDf1ASjRuVMuqSyrN19d/o0NoI7mMUdjoiIFEmziZeZfa+59e7+6+KG047ttFOYm6+QDvZbtoQary99qehhSTzW7rYbfPghLFmicbxERKpISzVevaL7vYCDCYMPApwEPNrWk7v7HGBOW49TNQqdLPuZZ8LgqRq/q2qs3W238ODZZ5V4iYhUkZYmyf6PaD7G4cCB7n6hu18IHATo26DYRo4MNV6+w/RxzWtqCvdKvKrGvxIvXdkoIlJV8h3HaxCwMe35xmiZFFNdHaxZA2+91br9mppCrYhqRqrG5p49wwCqSrxERKpKviPX/wV41MxujZ6fClxTioDatfTJsgcPzm8f95B4HX986eKSeIwZE5oaRUSkauQ7SfY04KvA+9Htq+7+81IG1i6NHBnuW9PBfuHCUEOmZsbqM3o0vPgibN7c8rYiIlIR8q3xwt2fAJ4oYSwyYgR07ty6Dvbq31W9Ro+GjRtDcr333nFHIyIiRZBvHy8ph06dYI89Wlfjdf/90L+/vpirUWrUejU3iohUDSVeSdPaybKbmuDwwzXIZjXae+8wqK462IuIVA0lXklTVxealrbmMX/4smXw2mtqZqxW3brBnnuqxktEpIoo8UqakSNhwwZYurTlbdW/q/qNGaMaLxGRKqLEK2lSQ0rk09zY1AQ9esABB5Q2JonP6NGhBnT9+rgjERGRIlDilTSpISXyubKxqQkOOyx0ypfqNHp0GKvthRfijkRERIpAiVfSDB0a+va0VOO1alXo+3PkkWUJS2KSurJRzY0iIlVBiVfSdOgQOlS3VOP14IOhJkT9u6rbHntAly5KvEREqoQSryRKTZbdnKamMNjquHHliUni0akT7LOPrmwUEakSSrySqK4uDBPR3FQxTU0wdmxolpTqpisbRUSqhhKvJKqrC0nXokXZ169fD489pmbG9mL0aHjzTXj//bgjERGRNlLilUQtTZb9yCOwaZMSr/Zi9Ohwr1ovEZGKp8QriVJjeeXqYN/UFKYI+sQnyheTxEdXNoqIVA0lXkk0cCD07p27xqupKdSC9O1b3rgkHsOHh8+DEi8RkYqnxCuJzHJPlr15Mzz0kJoZ2xOzkGjrykYRkYqnxCup6uqyNzU+9RSsWaOBU9ub1JWN7nFHIiIibaDEK6lGjoQ33oCPPtp+uSbGbp9Gjw5XNS5fHnckIiLSBkq8kqquLtRuvPrq9submmD33cPUQtJ+pK5sVHOjiEhFU+KVVNmGlHCHBx5QbVd7pCElRESqghKvpEoNKZGeeL38MqxcqcSrPerfHwYPVuIlIlLhlHglVd++0K/f9h3s778/3Cvxap90ZaOISMVT4pVkmZNlNzWFMb5StWHSvowZAy+8AFu2xB2JiIgUSIlXkmWO5dXUFGq7zOKLSeIzenSYp/P11+OORERECqTEK8lGjgyTI69dC0uWhOEl1MzYfunKRhGRiqfEK8lSTYoLF24bv0sDp7Zf++4b7tXBXkSkYinxSrL0ybKbmsJ8ffvtF29MEp8ePcIYbkq8REQqlhKvJEsfUqKpCT7+cejYMd6YJF66slFEpKIp8Uqynj1hyBB4+GF4/nn175JwZeMrr+w4lZSIiFQEJV5JV1cHM2eGx0q8ZPToMJzESy/FHYmIiBRAiVfSdeiwbdymSZOgvj7eeCRemjpIRKSiKfFKsvp6ePDBbc+XLIEpU5R8tWcjR0Lnzkq8REQqlBKvJJs6FTZt2n7ZunVhubRPO+0Ee+2lDvYFMrNdzOxeM1sQ3ffNsd1lZvZcdPtC2vJjzewJM3vKzB4wsz3LF72IVAMlXkm2eHHrlkv7MGaMarwKdzHQ6O51QGP0fDtm9mngQGB/YBxwkZn1jlZfAUxy9/2B64EflyFmEakiSrySbMSI1i2X9mH06DCLwerVcUdSiU4Bro0eXwucmmWbUcD97r7Z3dcCzwATonUOpJKwnYFlpQtVRKqREq8kmzYNunfffln37mG5tF+pDvbPPx9vHJVpkLsvjx6vAAZl2eZpYIKZdTez/sDRwK7RunOAmWa2FDgTuLTUAYtIdekUdwDSjEmTwv3UqaF5ccSIkHSllkv7NGZMuH/uOTjssHhjSSAzmw0MzrJqu86R7u5m5pkbufssMzsYmAesBB4CokuL+S4w0d0fMbPvA78mJGOZMUwBpgAMGjSIOXPm5B3/mjVrWrV9KSiGZMQQ9/kVQ2liUOKVdJMmKdGS7dXUhOmD1M8rK3c/Ltc6M3vLzIa4+3IzGwK8neMY04Bp0T7XA6+Y2QDgY+7+SLTZ34C7c+w/HZgOMHbsWB8/fnze8c+ZM4fWbF8KiiEZMcR9fsVQmhjU1ChSaTp0CBNm68rGQjQAk6PHk4HbMjcws45m1i96vB+wHzALeB/Y2cxGRpseD7xY8ohFpKqoxkukEo0ZAw0NcUdRiS4FbjKzs4E3gM8DmNlY4Dx3PwfoDDSZGcBq4Ax33xxt93Xg72a2lZCIfa38L0FEKpkSL5FKNHo0XH01vP02DBwYdzQVw93fBY7Nsvxxor5a7r6BcGVjtv1vBW4tZYwiUt3U1ChSiVJXNpayubG+HmprOeqYY6C2VjMmiIgUQdkTLzPb1cz+aWYvmNnzZnZBuWMQqXjpVzaWQn19mJ7qjTcw9zBumKarEhFpszhqvDYDF7r7KOBQ4JtmlrVaX0RyGDgQ+vcvXeI1dWqYniqdpqsSEWmzside7r7c3Z+IHn9IuCpoWLnjEKloZqG5sVRNjZquSkSkJGLtXG9mtcABwCNZ1hU0AGESBlpLl6R4khQLJCueJMUC+cWzZ9++DH7kER64774wxEQRHTpwIF3femuH5RsGDuThBL1PIiKVJrbEy8x6An8HvuPuO0w6V+gAhEkYaC1dkuJJUiyQrHiSFAvkGc8rr8CttzJ+991D5/di+tWv4KyzYPPmbcu6dqXrr36VqPdJRKTSxHJVo5l1JiRd9e5+SxwxiFS8Ul7ZePLJ0LEj9OiBh/GsYNw4zaIgItJGcVzVaMDVwIvu/utyn1+kaqQSr1J0sL/uOvjoI2hsZO5998E3vwnz5sHSpcU/l4hIOxJHjdcngDOBY8zsqeg2MYY4RCpb795h4vRiJ17ucMUVcMABcMghYdlFF8HWrfBr/VYSEWmLOK5qfMDdzd33c/f9o9vMcschUhVKcWXjvHnhmN/4Rrh6EkIfsi99CaZPh3ffLe75RETaEY1cL1LJxoyBl16CTZuKd8wrrgi1aV/+8vbLf/hDWLsWLr+8eOcSEWlnlHiJVLLRo0PStWBBcY73zjswYwZ85SvQo8eO5zrpJPjd70ICJiIirabES6SSFfvKxj//GTZuhPPOy77+kkvgvffgj38szvlERNoZJV4ilWzvvcOwD8XoYL91K1x5JRxxBOy7b/ZtDjsMjjwyjPO1cWPbzyki0s4o8RKpZF27Ql1dcWq87r0XXn01dKpvziWXhGElNGG2iEirKfESqXSjRxenxuuKK2DAADj99Oa3O+EE2H9/uOyyUEsmIiJ5U+IlUunGjIHXXmtbh/elS+H22+Hss6FLl+a3NYOLL4aXX4Z//KPwc4qItENKvEQq3ejRYdDTF14o/Bh//GM4xpQp+W3/mc/AHnvApZeG/UREJC9KvEQqXVunDtq0KSReEybAbrvlt0+nTvCDH8Bjj8F99xV2XhGRdkiJl0il22OP0Mm+0MSroQGWL2+5U32mr3wFBg8OtV4iIpIXJV4ila5jRxg1qvArG6+4Isz5OLGVU6Z27Qrf+x7Mng2PP17YuUVE2hklXiLVoNArG195BRobQ9+ujh1bv/+550KfPqr1EhHJkxIvkWowZkxoLmztBNZXXhn6a519dmHn7d0bvvlNuOWWMGekiIg0S4mXSDUopIP9+vVhiqDTTgt9tQp1/vlhCIpf/KLwY4iItBNKvESqQSGJ1003wfvvt75TfaaBA+Gcc+Cvfw3jgYmISE5KvESqwbBhoa9VaxKvP/whzPU4fnzbz3/hhWEU+1//uu3HEhGpYkq8RKqBWaj1yvfKxqeegocfhvPOC/u2VW0tfPnLMH166/uZiYi0I0q8RKrFmDGhxiufkeSvuAK6dQtjcRXLD38Ypi26/PLiHVNEpMoo8RKpFqNHwwcfwJtvNr/d6tVQXw9f/CL07Vu88++7L5x8Mvzud7BmTfGOKyJSRZR4iVSLVAf7lpob//rXUDPV1k712Vx8Mbz3Hlx1VfGPLSJSBZR4iVSLfK5sdA+d6g86CA4+uPgxHHYYHHUU/OpXsHFj8Y8vIlLhlHiJVItddoGhQ5tPvB58MKwvRW1XysUXh2El6utLdw4RkQqlxEukmrR0ZeMVV8DOO4f+XaVywgmw//5w2WWwZUvpziMiUoGUeIlUkzFj4IUXsic8K1fCzTeHKxl79ChdDGah1uvll+G220p3HhGRCqTES6SajB4NH30Er76647o//Sn0uzrvvNLH8dnPwh57wM9/nt/wFiIi7YQSL5FqkuvKxq1bw4TYRx0Fo0aVPo6OHeEHP4DHH4f77iv9+UREKoQSL5FqMmpUaOrL7GA/axa8/nppO9VnmjwZhgwJtV4iIgIo8RKpLt27hya+zBqvK64Ik1mfdlr5YunSBb77XWhshMceK995RUQSTImXSLUZPXr7Gq/Fi+GOO+Dss2Gnncoby7nnhqmJjjoKOnQIczpqmAkRaceUeIlUmzFjYMEC2LAhPP/jH0MH9ylTyh/L7bfDpk2wfn2I4Y03QhxKvkSknVLiJVJtRo8OnelffDEkPVddBRMnhtqmcps6FTZv3n7ZunVhuYhIO9Qp7gBEpMjSpw569VVYsaK8nerTLV7cuuUiIlVOiZdItamrC325nnsuDOdQUwMTJsQTy4gRoXkx23IRkXZITY0i1eamm0J/qv/93zCG1iGHhHG14jBtWrjSMl337mF5DMzsc2b2vJltNbOxzWw3wcxeNrOFZnZx2vLdzOyRaPnfzKzMVyuISKVT4iVSTerrQ+f1TZu2Lbvjjvg6s0+aBNOnh1o3s3A/fXpYHo/ngNOB+3NtYGYdgf8HfAoYBXzJzFKjzl4G/Mbd9wTeB84ubbgiUm2UeIlUk6lTQ+f1dOvXx9uZfdIkWLQodPhftCjOpAt3f9HdX25hs0OAhe7+mrtvBG4ETjEzA44Bbo62uxY4tWTBikhVUuIlUk3Umb0YhgFL0p4vjZb1A1a5++aM5SIieVPnepFqos7smNlsYHCWVVPd/bYyxTAFmAIwaNAg5syZk/e+a9asadX2paAYkhFD3OdXDKWJQYmXSDWZNi308UpvboyxM3sc3P24Nh7iTWDXtOfDo2XvAn3MrFNU65Vani2G6cB0gLFjx/r48ePzPvmcOXNozfaloBiSEUPc51cMpYlBTY0i1SR5ndkr0WNAXXQF407AF4EGd3fgn8Bno+0mA2WpQROR6qHES6TaJKgze9KY2WlmthQ4DLjTzO6Jlg81s5kAUW3Wt4B7gBeBm9z9+egQPwS+Z2YLCX2+ri73axCRyqamRhFpN9z9VuDWLMuXARPTns8EZmbZ7jXCVY8iIgVRjZeIiIhImSjxEhERESkTJV4iIiIiZRJL4pVrHjQRERGRalb2xKuFedBEREREqlYcNV5Z50GLIQ4RERGRsooj8co1D5qIiIhIVUvsOF7pc50Ba8zs5Tx37Q+8U5qoCpKkeJIUCyQrniTFAsmKJ45Yasp8vpKZP3/+O2aWZQLNnJLwt1cMyYgh7vMrhsJjyFmGxZF45ZoHbTvpc521hpk97u5jCw+vuJIUT5JigWTFk6RYIFnxJCmWSuTuA1qzfRLeb8WQjBjiPr9iKE0McTQ1Zp0HLYY4RERERMqq7DVe7r7ZzFLzoHUE/pQ2D5qIiIhI1Yqlj1euedCKpNXNkyWWpHiSFAskK54kxQLJiidJsbQHSXi/FUMQdwxxnx8UQ0rRYjB3L9axRERERKQZmjJIREREpEyqKvFKylREZrarmf3TzF4ws+fN7IK4YklnZh3N7EkzuyPmOPqY2c1m9pKZvWhmh8Ucz3ejv9NzZnaDmXUt8/n/ZGZvm9lzact2MbN7zWxBdN83xlh+Ef2tnjGzW82sTzliaW/iLr+SVG7FXVYloYyKo1xKQlmUhDIoWwxp6y40Mzez/oUev2oSr4RNRbQZuNDdRwGHAt9MyLRIFwAvxh0E8FvgbnffG/gYMcZkZsOA84Gx7j6acMHHF8scxjXAhIxlFwON7l4HNEbP44rlXmC0u+8HvAJcUqZY2o2ElF9JKrfiLqtiLaNiLJeuIf6yKFsM5S6DssWAme0KfBJY3JaDV03iRYKmInL35e7+RPT4Q8I/bayj85vZcODTwFUxx7EzcCRwNYC7b3T3VXHGRLjIpJuZdQK6A8vKeXJ3vx94L2PxKcC10eNrgVPjisXdZ7n75ujpw4Sx96S4Yi+/klJuxV1WJaiMKnu5lISyKAllUI73AeA3wA+ANnWOr6bEK5FTEZlZLXAA8EjMofwf4QOzNeY4dgNWAn+OmhKuMrMecQXj7m8CvyT8glkOfODus+KKJ80gd18ePV4BDIozmDRfA+6KO4gqlKjyK+Zy6/+It6yKvYxKWLmUtLIoljLIzE4B3nT3p9t6rGpKvBLHzHoCfwe+4+6rY4zjROBtd58fVwxpOgEHAle4+wHAWsrXjLaDqL/CKYTCdijQw8zOiCuebDxcehz75cdmNpXQHFUfdyxSOnGWWwkpq2Ivo5JaLsVdFsVVBplZd+BHwL8X43jVlHjlNRVRuZhZZ0LhVe/ut8QVR+QTwMlmtojQhHGMmV0XUyxLgaXunvolfTOhkIvLccDr7r7S3TcBtwAfjzGelLfMbAhAdP92nMGY2VnAicAk1xg0pZCI8isB5VYSyqoklFFJKpcSURbFXAbtQUiCn44+m8OBJ8xscCEHq6bEKzFTEZmZEfoHvOjuv44jhnTufom7D3f3WsL7cp+7x/Lryd1XAEvMbK9o0bHAC3HEElkMHGpm3aO/27Ek4wKEBmBy9HgycFtcgZjZBELTz8nuvi6uOKpc7OVXEsqtJJRVCSmjklQuxV4WxV0Gufuz7j7Q3Wujz+ZS4MDos9JqVZN4RR3vUlMRvQjcFONURJ8AziT8Wnsquk2MKZYk+jZQb2bPAPsD/xNXINGv2puBJ4BnCf8TZR0l2cxuAB4C9jKzpWZ2NnApcLyZLSD8+r00xlguB3oB90af5T+UI5b2JCHll8qtbWIto+Iql5JQFiWhDMoRQ/GOr1YDERERkfKomhovERERkaRT4iUiIiJSJkq8RERERMpEiZeIiIhImSjxEhERESkTJV5SVGa2JrqvNbMvF/nYP8p4Pq+YxxeR9k3ll5SDEi8plVqgVQVXNBlsc7YruNw9CSPMi0j1qUXll5SIEi8plUuBI6LB7r5rZh3N7Bdm9piZPWNm5wKY2XgzazKzBqLRoc3sH2Y238yeN7Mp0bJLgW7R8eqjZalfpxYd+zkze9bMvpB27DlmdrOZvWRm9dEo0CIizVH5JSXTUoYuUqiLgYvc/USAqAD6wN0PNrMuwINmNiva9kBgtLu/Hj3/mru/Z2bdgMfM7O/ufrGZfcvd989yrtMJo0t/DOgf7XN/tO4AYF9gGfAgYXTuB4r9YkWkqqj8kpJRjZeUyyeBr5jZU8AjQD+gLlr3aFqhBXC+mT0NPEyYOLiO5h0O3ODuW9z9LWAucHDasZe6+1bgKUITgohIa6j8kqJRjZeUiwHfdvd7tltoNh5Ym/H8OOAwd19nZnOArm0470dpj7egz7yItJ7KLyka1XhJqXxImNQ05R7gG2bWGcDMRppZjyz77Qy8HxVaewOHpq3blNo/QxPwhagfxgDgSODRorwKEWmPVH5JySh7llJ5BtgSVblfA/yWUE3+RNRBdCVwapb97gbOM7MXgZcJ1fUp04FnzOwJd5+UtvxW4DDgacCBH7j7iqjgExFpLZVfUjLm7nHHICIiItIuqKlRREREpEyUeImIiIiUiRIvERERkTJR4iUiIiJSJkq8RERERMpEiZeIiIhImSjxEhERESkTJV4iIiIiZfL/A0jC0NuuJx+/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bo.plot_convergence()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. create different kernels optimization process\n",
    "why are h-p are optimized for kernels they do not required\n",
    "why the diff is the same for kernels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3d1baa44583d8ec46d9c51771f1212390b5783b843e583a1bb6c33531f0efe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
