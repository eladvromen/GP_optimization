{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERT_PATH = '..\\\\research\\data_expert_demo.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_data = pd.read_hdf(EXPERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>username</th>\n",
       "      <th>practice_mode</th>\n",
       "      <th>bpm</th>\n",
       "      <th>error_before_left_timing</th>\n",
       "      <th>error_before_right_timing</th>\n",
       "      <th>error_before_left_pitch</th>\n",
       "      <th>error_before_right_pitch</th>\n",
       "      <th>error_after_left_timing</th>\n",
       "      <th>error_after_right_timing</th>\n",
       "      <th>error_after_left_pitch</th>\n",
       "      <th>error_after_right_pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>song1.mid</td>\n",
       "      <td>elad_demo_0</td>\n",
       "      <td>IMP_TIMING</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_PITCH</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83b_HaAviv.midi</td>\n",
       "      <td>elad_demo_01</td>\n",
       "      <td>IMP_TIMING</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     midi_filename      username practice_mode   bpm   \n",
       "0        song1.mid   elad_demo_0    IMP_TIMING  75.0  \\\n",
       "1  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "2  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "3  83b_HaAviv.midi  elad_demo_01     IMP_PITCH  85.0   \n",
       "4  83b_HaAviv.midi  elad_demo_01    IMP_TIMING  85.0   \n",
       "\n",
       "   error_before_left_timing  error_before_right_timing   \n",
       "0                       0.0                   0.036429  \\\n",
       "1                       0.0                   0.078066   \n",
       "2                       0.0                   0.049352   \n",
       "3                       0.0                   0.040376   \n",
       "4                       0.0                   0.021390   \n",
       "\n",
       "   error_before_left_pitch  error_before_right_pitch  error_after_left_timing   \n",
       "0                      0.0                  0.000000                      0.0  \\\n",
       "1                      0.0                  0.152778                      0.0   \n",
       "2                      0.0                  0.250000                      0.0   \n",
       "3                      0.0                  0.013889                      0.0   \n",
       "4                      0.0                  0.000000                      0.0   \n",
       "\n",
       "   error_after_right_timing  error_after_left_pitch  error_after_right_pitch  \n",
       "0                  0.030571                     0.0                 0.000000  \n",
       "1                  0.049352                     0.0                 0.250000  \n",
       "2                  0.040376                     0.0                 0.013889  \n",
       "3                  0.021390                     0.0                 0.000000  \n",
       "4                  0.017971                     0.0                 0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "Error = namedtuple(\"Error\", \"pitch timing\")\n",
    "\n",
    "BPM_BOUNDS = [50,200]\n",
    "\n",
    "#### SIMPLIFIED ENUMS\n",
    "import enum\n",
    "class PracticeMode(enum.Enum):\n",
    "    IMP_PITCH = enum.auto()\n",
    "    IMP_TIMING = enum.auto()\n",
    "    \n",
    "class NoteRangePerHand(enum.Enum):\n",
    "    EASY = 0.5\n",
    "    MEDIUM = 1.5\n",
    "    HARD = 3.0\n",
    "    \n",
    "\n",
    "import dataclasses as dc\n",
    "from dataclasses import dataclass, astuple    \n",
    "@dataclass\n",
    "class TaskParameters:\n",
    "    \"\"\"\n",
    "    We need to redefine this to use the new, simplified NoteRangePerHand.\n",
    "    \n",
    "    \n",
    "    TODO: Should we include the parameters we are not using here?\n",
    "        maybe just clarify which one we are using in this simplified case\n",
    "    \"\"\"\n",
    "    \n",
    "    ## USED IN SIMPLIFIED CASE\n",
    "    bpm: float              = 120\n",
    "    note_range: NoteRangePerHand = NoteRangePerHand.MEDIUM\n",
    "    \n",
    "    ## UNUSED HERE, but used in real application\n",
    "    timeSignature: tuple    = (4,4)\n",
    "    noteValues: list        = dc.field(default_factory= lambda: [1, 1 / 2, 1 / 4, 1 / 8] )\n",
    "    maxNotesPerBar: int       = 3\n",
    "    noOfBars: int           = 7\n",
    "    note_range: NoteRangePerHand = NoteRangePerHand.MEDIUM\n",
    "    left: bool              = False\n",
    "    right: bool             = True\n",
    "    \n",
    "    \n",
    "    def astuple(self):\n",
    "        return astuple(self)\n",
    "    \n",
    "\n",
    "## Mappings of categorical data to ints.\n",
    "### The pracice modes will be mapped onto a single dimension, placed far away\n",
    "### from each other\n",
    "practicemode2int = {pm: i*1000 for i, pm in enumerate(PracticeMode)}\n",
    "int2practicemode = {i*1000: pm for i, pm in enumerate(PracticeMode)}\n",
    "    \n",
    "### The note range will be one-hot encoded, but we still need dicts to convert\n",
    "noterange2int = {pm: i for i, pm in enumerate(NoteRangePerHand)}\n",
    "int2noterange = {i: pm for i, pm in enumerate(NoteRangePerHand)}\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import GPyOpt\n",
    "import GPy\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPPlotData:\n",
    "    X1: np.array = None\n",
    "    X2: np.array = None\n",
    "    mean: np.array = None \n",
    "    mean_max: float = None\n",
    "    mean_min: float = None\n",
    "    std: np.array = None\n",
    "    std_max: float = None\n",
    "    std_min: float = None\n",
    "    acq: np.array = None\n",
    "    acq_max: float = None\n",
    "    acq_min: float = None\n",
    "    \n",
    "    def apply_to_arrays(self, func):\n",
    "        return [\n",
    "            func(self.mean),\n",
    "            func(self.std),\n",
    "            func(self.acq),\n",
    "            ]\n",
    "\n",
    "\n",
    "class GaussianProcess:\n",
    "    def __init__(self, bpm_norm_fac=100):\n",
    "        self.data_X = None#should be the task parameters\n",
    "        self.data_X_old_shape = None\n",
    "        \n",
    "        self.data_Y = None#should be the error after\n",
    "        \n",
    "        self.bpm_norm_fac = bpm_norm_fac\n",
    "        \n",
    "        self.domain =[\n",
    "            {'name': 'complexity_level', 'type': 'discrete', 'domain': tuple(range(10))},\n",
    "            {'name': 'practice_mode', 'type': 'discrete', 'domain': tuple(i*1000 for i , _ in enumerate(PracticeMode))},\n",
    "            {'name': 'note_range', 'type': 'categorical', 'domain': (0,1,2)},\n",
    "            {'name': 'bpm', 'type': 'continuous', 'domain': \n",
    "                 (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))},\n",
    "                 \n",
    "                ]\n",
    "                 \n",
    "       \n",
    "        self.space = GPyOpt.core.task.space.Design_space(self.domain)\n",
    "        \n",
    "    def _norm_bpm(self, v):\n",
    "        return v/self.bpm_norm_fac\n",
    "        \n",
    "    def _params2domain(self, complexity_level, task_parameters, practice_mode):\n",
    "        domain_x = [complexity_level,\n",
    "                    practicemode2int[practice_mode],\n",
    "                    noterange2int[task_parameters.note_range],\n",
    "                    self._norm_bpm(task_parameters.bpm),\n",
    "                    ]\n",
    "        \n",
    "        \n",
    "        return np.array([domain_x])\n",
    "        \n",
    "    def _domain2space(self, domain_x):\n",
    "        ## Converts the domain variables into the GPs input space\n",
    "        ## does one-hot encoding\n",
    "        space_rep = self.space.unzip_inputs(domain_x)\n",
    "        return space_rep\n",
    "    \n",
    "        \n",
    "    def _get_bayes_opt(self):\n",
    "        return self.bayes_opt\n",
    "        \n",
    "    \n",
    "    def update_model(self):\n",
    "\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        # kernel = GPy.kern.RBF(input_dim=self.space.model_dimensionality, \n",
    "        #                       variance=0.01, \n",
    "        #                       lengthscale=1)\n",
    "\n",
    "\n",
    "        #here to add modularity- different kernels for different  hyperparameters\n",
    "        \n",
    "        kernel = GPy.kern.Matern52(input_dim=self.space.model_dimensionality, \n",
    "                              variance=0.01, \n",
    "                              lengthscale=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt._update_model() \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt._update_model() \n",
    "        \n",
    "#experimental\n",
    "\n",
    "    def update_model_with_kernel(self, kernel):\n",
    "    #it seems possible to enter the kernel to the functionality...\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        \n",
    "        \n",
    "    #sort of predict that gives utility\n",
    "    def get_estimate(self, complexity_level, task_parameters, practice_mode,\n",
    "                     add_variance=True):\n",
    "        if not hasattr(self, \"bayes_opt\"):\n",
    "            # if there is no model yet, e.g. in the first iteration\n",
    "            # print(\"(GP) DATA_X IS NONE, RETURNING RANDOM NUMBER\")\n",
    "            return random.random()\n",
    "        \n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        X = self._params2domain(complexity_level, task_parameters, practice_mode)\n",
    "        X = self._domain2space(X)\n",
    "        \n",
    "        mean, var = bayes_opt.model.predict(X)\n",
    "        \n",
    "        r = mean[0]\n",
    "        if add_variance:\n",
    "            r += np.sqrt(var[0])\n",
    "        return r\n",
    "        \n",
    "    #choose the best practice mode from utility estimate\n",
    "    def get_best_practice_mode(self, complexity_level, task_parameters):\n",
    "        all_practice_modes = list(PracticeMode)\n",
    "        if random.random() > 0.05:\n",
    "            max_i = np.argmax([self.get_estimate(complexity_level, task_parameters, pm)\n",
    "                                             for pm in all_practice_modes])\n",
    "            return all_practice_modes[max_i]\n",
    "        \n",
    "        else:\n",
    "            # use weighted choice based on softmax\n",
    "            # increases exploration\n",
    "            def softmax(x):\n",
    "                return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            \n",
    "            return random.choices(all_practice_modes, \n",
    "                                  softmax(\n",
    "                [0.5*self.get_estimate(complexity_level, task_parameters, pm)\n",
    "                                             for pm in all_practice_modes]), k=1)[0]\n",
    "            \n",
    "    \n",
    "    def add_data_point(self, complexity_level, task_parameters, practice_mode, \n",
    "                       utility_measurement):\n",
    "        new_x =  self._params2domain(complexity_level, task_parameters, practice_mode) \n",
    "        new_y = [ utility_measurement ]\n",
    "        \n",
    "        if self.data_X is None:\n",
    "            self.data_X = new_x\n",
    "            self.data_Y = [new_y]\n",
    "        else:\n",
    "            self.data_X = np.vstack((self.data_X, new_x[0]))\n",
    "            self.data_Y = np.vstack((self.data_Y, new_y[0]))\n",
    "    \n",
    "    def get_policy(self, c):\n",
    "        if not hasattr(self, \"bayes_opt\"):\n",
    "            return np.round(np.random.random((3*150,1)))\n",
    "        \n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        data_dict = defaultdict(GPPlotData)\n",
    "        for i, practice_mode in enumerate([PracticeMode.IMP_TIMING,\n",
    "                                           PracticeMode.IMP_PITCH]):\n",
    "            # insert plot data into the data_dict\n",
    "            self._get_plot_data(data_dict, c, practice_mode, bayes_opt)\n",
    "            \n",
    "        return np.argmax([d.mean for d in [\n",
    "            data_dict[PracticeMode.IMP_TIMING], data_dict[PracticeMode.IMP_PITCH]]], axis=0)\n",
    "    \n",
    "    \n",
    "    def _get_plot_data(self, data_dict, c, practice_mode, bayes_opt, for_plot=False):\n",
    "        bounds = [[0,3], (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))]\n",
    "        \n",
    "        acquisition_function = bayes_opt.acquisition.acquisition_function\n",
    "        model = bayes_opt.model\n",
    "        \n",
    "        if not for_plot:\n",
    "            X1 = np.array([0,1,2])\n",
    "            X1_axis = X1\n",
    "            reshape_dim = 3*150\n",
    "        else:\n",
    "            X1_axis = np.linspace(bounds[0][0], bounds[0][1], 150, endpoint=False)\n",
    "            X1 = np.array([0]*50 + [1]*50 + [2]*50)\n",
    "            reshape_dim = 150*150\n",
    "            \n",
    "        X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "        \n",
    "        x1, x2 = np.meshgrid(X1, X2)\n",
    "        X = np.hstack((\n",
    "            \n",
    "            np.array([c]*(reshape_dim)).reshape(reshape_dim,1),\n",
    "            np.array([practicemode2int[practice_mode]]*(reshape_dim)).reshape(reshape_dim,1),\n",
    "            x1.reshape(reshape_dim,1),\n",
    "             x2.reshape(reshape_dim,1)))\n",
    "        \n",
    "        X_spaced = self._domain2space(X)\n",
    "         \n",
    "        acqu = acquisition_function(X_spaced)\n",
    "        \n",
    "        m, v = model.predict(X_spaced)\n",
    "        \n",
    "        if type(m) == list:\n",
    "            m = m[0]\n",
    "        \n",
    "        if type(v) == list:\n",
    "            v = v[0]\n",
    "        \n",
    "        if type(acqu) == list:\n",
    "            acqu = acqu[0]\n",
    "        \n",
    "        data_dict[practice_mode].mean = m\n",
    "        data_dict[practice_mode].std = np.sqrt(v)\n",
    "        data_dict[practice_mode].acq = acqu\n",
    "        data_dict[practice_mode].X1 = X1_axis\n",
    "        data_dict[practice_mode].X2 = X2\n",
    "        \n",
    "    \n",
    "    def _plot_single_practice_mode(self, gp_plot_data, subplotf,\n",
    "                                   plot_mean=True,\n",
    "                                   plot_std=True,\n",
    "                                   plot_acq=True):\n",
    "        label_x = \"NoteRange\"\n",
    "        label_y = \"BPM\"\n",
    "        \n",
    "        X_TICKS = ([0.5,1.5,2.5], [\"0\", \"1\", \"2\"])\n",
    "        \n",
    "        bounds = [[0,3], (self._norm_bpm(BPM_BOUNDS[0]),self._norm_bpm(BPM_BOUNDS[1]))]\n",
    "        \n",
    "        ## Derived from GPyOpt/plotting/plots_bo.py\n",
    "        X1 = gp_plot_data.X1\n",
    "        X2 = gp_plot_data.X2\n",
    "        \n",
    "        def inflate_array(a):\n",
    "            return a.reshape((150,150))\n",
    "        \n",
    "        subplot_count = 0\n",
    "        \n",
    "        if plot_mean:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.mean),100,\n",
    "                         vmin=gp_plot_data.mean_min,\n",
    "                         vmax=gp_plot_data.mean_max,)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Posterior mean')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "        ##\n",
    "        \n",
    "        if plot_std:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.std),100,\n",
    "                         vmin=gp_plot_data.std_min,\n",
    "                         vmax=gp_plot_data.std_max)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Posterior sd.')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "        ##\n",
    "        \n",
    "        \n",
    "        if plot_acq:\n",
    "            subplot_count += 1\n",
    "            subplotf(subplot_count)\n",
    "            plt.contourf(X1, X2, inflate_array(gp_plot_data.acq),100,\n",
    "                         vmin=gp_plot_data.acq_min,\n",
    "                         vmax=gp_plot_data.acq_max,)\n",
    "            plt.colorbar()\n",
    "            plt.xlabel(label_x)\n",
    "            plt.ylabel(label_y)\n",
    "            plt.title('Acquisition function')\n",
    "            plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "            plt.xticks(*X_TICKS)\n",
    "            \n",
    "    \n",
    "    def plot_mutiple(self, c, practice_modes,\n",
    "                                   plot_mean=True,\n",
    "                                   plot_std=True,\n",
    "                                   plot_acq=False):\n",
    "        bayes_opt = self._get_bayes_opt()\n",
    "        \n",
    "        n_rows = len(practice_modes)\n",
    "        n_cols = sum([plot_mean, plot_std, plot_acq])\n",
    "        \n",
    "        data_dict = defaultdict(GPPlotData)\n",
    "        for i, practice_mode in enumerate(practice_modes):\n",
    "            self._get_plot_data(data_dict, c, practice_mode, bayes_opt,\n",
    "                                for_plot=True)\n",
    "            \n",
    "        mean_max, std_max, acq_max = np.max([d.apply_to_arrays(np.max) for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        mean_min, std_min, acq_min = np.min([d.apply_to_arrays(np.min) for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        for pd in data_dict.values():\n",
    "            pd.mean_max = mean_max\n",
    "            pd.mean_min = mean_min\n",
    "            pd.std_max = std_max\n",
    "            pd.std_min = std_min\n",
    "            pd.acq_max = acq_max\n",
    "            pd.acq_min = acq_min\n",
    "        \n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(n_cols*3.34,5*n_rows))\n",
    "        \n",
    "        for i, practice_mode in enumerate(practice_modes):\n",
    "            subplotf = lambda idx: plt.subplot(n_rows,n_cols,i*n_cols+idx)\n",
    "            self._plot_single_practice_mode(data_dict[practice_mode], subplotf,\n",
    "                                            plot_mean=plot_mean,\n",
    "                                            plot_std=plot_std,\n",
    "                                            plot_acq=plot_acq)\n",
    "            \n",
    "            ax = subplotf(1)\n",
    "            row = practice_mode.name\n",
    "            pad = 5\n",
    "            ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                        xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                        size='large', ha='right', va='center')\n",
    "        \n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.savefig(\"detailed_noise05.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        some_pd = list(data_dict.values())[0]\n",
    "        \n",
    "        argmax_plot_data = GPPlotData(X1=some_pd.X1, X2=some_pd.X2)\n",
    "        argmax_plot_data.mean = np.argmax([d.mean for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        argmax_plot_data.std = np.argmax([d.std for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        argmax_plot_data.acq = np.argmax([d.acq for d in \n",
    "                                             data_dict.values()], axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        subplotf = lambda idx: plt.subplot(1,3,idx)\n",
    "        \n",
    "        self._plot_single_practice_mode(argmax_plot_data, subplotf)\n",
    "        ax = subplotf(1)\n",
    "        row = \"ARGMAX\"\n",
    "        pad = 5\n",
    "        ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                    xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                    size='large', ha='right', va='center')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def gen_tasks(num_tasks=None, seed=546354):\n",
    "    assert num_tasks != None\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    for i in range(num_tasks):\n",
    "        bpm = rng.integers(*BPM_BOUNDS) \n",
    "        note_range = rng.choice(NoteRangePerHand)\n",
    "    \n",
    "        yield TaskParameters(bpm=bpm, note_range=note_range)\n",
    "    \n",
    "def task2error(task_parameters):\n",
    "    return Error(pitch=task_parameters.note_range.value,\n",
    "                timing=task_parameters.bpm/100\n",
    "                 )\n",
    "\n",
    "def task2error2(np_array):\n",
    "    def note_range_map(v):\n",
    "        import math\n",
    "        return [NoteRangePerHand.EASY.value, NoteRangePerHand.MEDIUM.value, \n",
    "                NoteRangePerHand.HARD.value][int(math.floor(v))]\n",
    "    \n",
    "    out = [[note_range_map(nr), bpm/100] for nr, bpm in np_array]\n",
    "    return np.array(out)\n",
    "\n",
    "    \n",
    "def per_after_practice(practice_mode, error):\n",
    "    if practice_mode == PracticeMode.IMP_PITCH:\n",
    "        return perf_after_pitch_practice(error)\n",
    "    if practice_mode == PracticeMode.IMP_TIMING:\n",
    "        return perf_after_timing_practice(error)\n",
    "    raise Exception()\n",
    "\n",
    "def perf_after_pitch_practice(error):\n",
    "    return Error(timing=error.timing,\n",
    "                 pitch=error.pitch*0.5)\n",
    "\n",
    "def perf_after_timing_practice(error):\n",
    "    return Error(timing=error.timing*0.5,\n",
    "                 pitch=error.pitch)\n",
    "\n",
    "def error_diff_to_utility(error_pre, error_post):\n",
    "    diff_timing = error_post.timing - error_pre.timing\n",
    "    diff_pitch  = error_post.pitch  - error_pre.pitch\n",
    "    \n",
    "    \n",
    "    MEAN_UTILITY = 0.75\n",
    "    \n",
    "    return - (diff_timing*1 + diff_pitch*1) - MEAN_UTILITY\n",
    "\n",
    "\n",
    "def calc_optimal_policy(performance):\n",
    "    bounds = [[0,3], BPM_BOUNDS]\n",
    "            \n",
    "    X1 = np.array([0,1,2])\n",
    "    X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "    x1, x2 = np.meshgrid(X1, X2)\n",
    "    X = np.hstack((    \n",
    "         x1.reshape(3*150,1),\n",
    "          x2.reshape(3*150,1)))\n",
    "    \n",
    "    error2d = task2error2(X)\n",
    "    error2d = np.array([performance(Error(*err)) for err in error2d])\n",
    "    \n",
    "    err_post_pitch = np.array(\n",
    "        [perf_after_pitch_practice(Error(*err)) for err in error2d])\n",
    "    \n",
    "    err_post_timing = np.array(\n",
    "        [perf_after_timing_practice(Error(*err)) for err in error2d])\n",
    "    \n",
    "    \n",
    "    argmax = np.argmin(np.vstack((\n",
    "        np.sum(err_post_timing, axis=1),\n",
    "        np.sum(err_post_pitch, axis=1)\n",
    "        )), axis=0)\n",
    "    \n",
    "    \n",
    "    error_diff = np.array([timing-pitch for timing, pitch in\n",
    "                          zip(\n",
    "        np.sum(err_post_timing, axis=1),\n",
    "        np.sum(err_post_pitch, axis=1))])\n",
    "    \n",
    "    return argmax.reshape(3*150,1), np.abs(error_diff.reshape(3*150,1))\n",
    "\n",
    "def compare_to_best_policy(policy_argmax, best_argmax, best_error_diff=1):\n",
    "    num_diff_cases = np.sum(np.abs(policy_argmax-best_argmax))\n",
    "    \n",
    "    abs_diff = num_diff_cases / policy_argmax.shape[0]\n",
    "    #weighted_diff = np.sum(best_error_diff[policy_argmax!=best_argmax]) / \\\n",
    "     #                       (np.median(best_error_diff) * best_error_diff.shape[0])\n",
    "    \n",
    "    return abs_diff #, weighted_diff\n",
    "\n",
    "def plot_best_policy():\n",
    "    label_x = \"NoteRange\"\n",
    "    label_y = \"BPM\"\n",
    "    \n",
    "    bounds = [[0,3], BPM_BOUNDS]\n",
    "    X_TICKS = ([0.5,1.5,2.5], [\"0\", \"1\", \"2\"])\n",
    "    \n",
    "    X1 = np.linspace(bounds[0][0], bounds[0][1], 150, endpoint=False)\n",
    "    X2 = np.linspace(bounds[1][0], bounds[1][1], 150)\n",
    "    x1, x2 = np.meshgrid(X1, X2)\n",
    "    X = np.hstack((    \n",
    "         x1.reshape(150*150,1),\n",
    "          x2.reshape(150*150,1)))\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    for idx, performance in enumerate([perf_bad_pitch, perf_balanced,\n",
    "                                       perf_bad_timing]):\n",
    "        title = [\"Bad Pitch\", \"Balanced\", \"Bad Timing\"][idx]\n",
    "        \n",
    "        error2d = task2error2(X)\n",
    "        error2d = np.array([performance(Error(*err)) for err in error2d])\n",
    "        \n",
    "        err_post_pitch = np.array(\n",
    "            [perf_after_pitch_practice(Error(*err)) for err in error2d])\n",
    "        \n",
    "        err_post_timing = np.array(\n",
    "            [perf_after_timing_practice(Error(*err)) for err in error2d])\n",
    "        \n",
    "        \n",
    "        argmax = np.argmin(np.vstack((\n",
    "            np.sum(err_post_timing, axis=1),\n",
    "            np.sum(err_post_pitch, axis=1)\n",
    "            )), axis=0)\n",
    "        \n",
    "        \n",
    "        plt.subplot(1, 3, idx+1)\n",
    "        plt.contourf(X1, X2, argmax.reshape(150,150),50,)\n",
    "        plt.xlabel(label_x)\n",
    "        if idx == 0:\n",
    "            plt.ylabel(label_y)\n",
    "        plt.title(title)\n",
    "        plt.axis((bounds[0][0],bounds[0][1],bounds[1][0],bounds[1][1]))\n",
    "        plt.xticks(*X_TICKS)\n",
    "        \n",
    "        if idx == 0:\n",
    "            from matplotlib.patches import Patch\n",
    "            cmap = plt.cm.viridis\n",
    "            custom_lines = [Patch(facecolor=cmap(1.)),\n",
    "                        Patch(facecolor=cmap(0.)),]\n",
    "            plt.legend(custom_lines, [\"IMP_PITCH\", \"IMP_TIMING\"])\n",
    "        \n",
    "    # plt.savefig(\"optimal_policies.eps\")\n",
    "    plt.show()\n",
    "    \n",
    "def single_experiment_run_tup(inp_tup, num_rounds):\n",
    "        performer, noise_var, bpm_norm_fac = inp_tup\n",
    "        gp, policy_diffs, kernel_params = single_experiment_run(\n",
    "                                    num_rounds=num_rounds, \n",
    "                                    performer=performer, \n",
    "                                    task_err_noise_var=noise_var, \n",
    "                                    utility_noise_var=noise_var, \n",
    "                                    bpm_norm_fac=bpm_norm_fac)\n",
    "        return (performer, noise_var, bpm_norm_fac), policy_diffs\n",
    "\n",
    "def single_experiment_run(num_rounds, \n",
    "                          performer, \n",
    "                          task_err_noise_var, utility_noise_var,\n",
    "                          bpm_norm_fac,\n",
    "                          seed=None,\n",
    "                          plot=False,\n",
    "                          print_details=False):\n",
    "    \n",
    "    if print_details:\n",
    "        from tqdm import tqdm\n",
    "    else:\n",
    "        def tqdm(iterable, **kwargs):\n",
    "            for x in iterable:\n",
    "                yield(x)\n",
    "    \n",
    "    seed = seed or random.randint(0, 2**16)\n",
    "    \n",
    "    performance_dict = dict(bad_pitch=perf_bad_pitch,\n",
    "                            balanced=perf_balanced,\n",
    "                            bad_timing=perf_bad_timing)\n",
    "    \n",
    "    perf_string = str(performer)\n",
    "    performer = performance_dict[perf_string]\n",
    "    \n",
    "    best_policy = calc_optimal_policy(performer)\n",
    "    policy_diffs = list()\n",
    "    kernel_params = list()\n",
    "    \n",
    "    GP = GaussianProcess(bpm_norm_fac=bpm_norm_fac)\n",
    "    c = 0\n",
    "    \n",
    "    for idx, tp in enumerate(tqdm(gen_tasks(num_rounds, seed=seed), \n",
    "                                  total=num_rounds)):\n",
    "        if idx % 3 == 0:\n",
    "            _pre = time.time()\n",
    "            \n",
    "            GP.update_model()\n",
    "            policy_diff = compare_to_best_policy(GP.get_policy(c),\n",
    "                *best_policy)\n",
    "            \n",
    "        \n",
    "        if hasattr(GP, \"bayes_opt\"):\n",
    "            kernel_params.append(list(map(lambda a:a.values[0],\n",
    "                    GP.bayes_opt.model.model.kern.parameters)))\n",
    "        \n",
    "        policy_diffs.append(policy_diff[1]) # only use weighted diff \n",
    "        \n",
    "        task_error = task2error(tp)\n",
    "        \n",
    "        task_error = Error(\n",
    "            pitch=task_error.pitch* random.gauss(1,task_err_noise_var),\n",
    "            timing=task_error.timing* random.gauss(1,task_err_noise_var),)\n",
    "        \n",
    "        \n",
    "        error_pre = performer(task_error)\n",
    "        given_practice_mode = GP.get_best_practice_mode(c, tp)\n",
    "        error_post = per_after_practice(given_practice_mode, error_pre)\n",
    "        utility = error_diff_to_utility(error_pre, error_post)\n",
    "        \n",
    "        utility *= random.gauss(1,utility_noise_var)\n",
    "        \n",
    "        GP.add_data_point(c, tp, given_practice_mode, utility)\n",
    "        \n",
    "        if print_details:\n",
    "            tqdm.write(\"\\n\")\n",
    "            tqdm.write(f\"NoteRange = {tp.note_range}\")\n",
    "            tqdm.write(f\"BPM = {tp.bpm}\")\n",
    "            tqdm.write(f\"Suggested PracticeMode: {given_practice_mode}\")\n",
    "            tqdm.write(f\"Error Pre: {error_pre}\")\n",
    "            tqdm.write(f\"Error post: {error_post}\")\n",
    "            tqdm.write(f\"Utility: {utility}\")\n",
    "            tqdm.write(f\"Policy Diff: {policy_diff}\")\n",
    "            tqdm.write(\"-\"*32)\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        GP.plot_mutiple(c, [\n",
    "            \n",
    "            PracticeMode.IMP_TIMING,\n",
    "            PracticeMode.IMP_PITCH,\n",
    "            ])\n",
    "        \n",
    "        plt.plot(list(range(len(policy_diffs))), policy_diffs)\n",
    "        plt.ylim((-0.01,None))\n",
    "        plt.show()\n",
    "        \n",
    "    return GP, policy_diffs, kernel_params\n",
    "\n",
    "def run_all_combinations():\n",
    "    num_per_comb = 27\n",
    "    performers = [\"bad_pitch\", \"balanced\", \"bad_timing\"]\n",
    "    noise_vars = [0.0, 0.25, 0.5] # [0.0, 0.1] #\n",
    "    bpm_norm_facs = [100] #1\n",
    "    \n",
    "    NUM_ROUNDS = 50\n",
    "    \n",
    "    comb = list()\n",
    "    for performer, noise_var, bpm_norm_fac in itertools.product(performers, \n",
    "                                                                 noise_vars,\n",
    "                                                                 bpm_norm_facs):\n",
    "        comb.extend([(performer, noise_var, bpm_norm_fac)]*num_per_comb)\n",
    "        \n",
    "    from multiprocessing import Pool\n",
    "    pool = Pool(2)\n",
    "    \n",
    "    import functools\n",
    "    single_exp = functools.partial(single_experiment_run_tup, \n",
    "                                             num_rounds=NUM_ROUNDS)\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    results = list()\n",
    "    for res in tqdm(pool.imap_unordered(single_exp, comb),\n",
    "                    total=len(comb),\n",
    "                    smoothing=0):\n",
    "    # for res in tqdm(map(single_exp, comb), # for debugging\n",
    "    #             total=len(comb),\n",
    "    #             smoothing=0):\n",
    "        results.append(res)\n",
    "        \n",
    "    res_dicts = list()\n",
    "    for run_idx, ((performer, noise_var, bpm_norm_fac), diffs) in enumerate(results):\n",
    "        pre_dict = dict(run_idx=run_idx,\n",
    "                        performer=performer,\n",
    "                        noise_var=noise_var,\n",
    "                        bpm_norm_fac=bpm_norm_fac)\n",
    "        for idx, val in enumerate(diffs):\n",
    "            d = pre_dict.copy()\n",
    "            d[\"iteration\"] = idx+1\n",
    "            d[\"policy_loss\"] = val\n",
    "            \n",
    "            res_dicts.append(d)\n",
    "            \n",
    "    return res_dicts\n",
    "        \n",
    "    \n",
    "def single_test_run():\n",
    "    STARTING_COMPLEXITY_LEVEL = 0\n",
    "    c = STARTING_COMPLEXITY_LEVEL\n",
    "    \n",
    "    performer = \"bad_timing\"\n",
    "    # performer = \"bad_pitch\"\n",
    "    # performer = \"balanced\"\n",
    "    \n",
    "    task_err_noise_var = 0.5\n",
    "    utility_noise_var  = 0.5\n",
    "     \n",
    "    TARGET_LOSS = 0.0\n",
    "    \n",
    "    for idx in range(100):\n",
    "        print(str(idx).center(64, \"=\"))\n",
    "        \n",
    "        GP, policy_diffs, kernel_params = single_experiment_run(\n",
    "            num_rounds=100, \n",
    "            performer=performer, \n",
    "            task_err_noise_var=task_err_noise_var, \n",
    "            utility_noise_var=utility_noise_var, \n",
    "            bpm_norm_fac=100,\n",
    "            plot=False,\n",
    "            print_details=True)\n",
    "        \n",
    "            \n",
    "        if policy_diffs[-1] >= TARGET_LOSS:\n",
    "            GP.plot_mutiple(c, [\n",
    "                \n",
    "                PracticeMode.IMP_TIMING,\n",
    "                PracticeMode.IMP_PITCH,\n",
    "                ])\n",
    "            \n",
    "            plt.plot(list(range(len(policy_diffs))), policy_diffs)\n",
    "            plt.ylim((-0.01,None))\n",
    "            plt.show()\n",
    "            \n",
    "            plt.plot(list(range(len(kernel_params))), kernel_params)\n",
    "            plt.legend([\"variance\", \"lengthscale\"])\n",
    "            plt.ylim((-0.01,None))\n",
    "            plt.show()\n",
    "            \n",
    "            break\n",
    "\n",
    "def run_combs_and_plot():\n",
    "    results = run_all_combinations()\n",
    "    \n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "    df = df.rename(columns={\"performer\": \"human-learner\"})\n",
    "\n",
    "    sns.relplot(\n",
    "        data=df,\n",
    "        x=\"iteration\", y=\"policy_loss\",\n",
    "        hue=\"noise_var\",\n",
    "        # hue=\"noise_var\",\n",
    "        col=\"human-learner\",\n",
    "        kind=\"line\",\n",
    "        ci=68,\n",
    "    )\n",
    "\n",
    "    # plt.ylim((None,0.8))\n",
    "    plt.xlim((1,50))\n",
    "    # plt.savefig(\"performers.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_diff_to_utility_for_opt(error_pre_pitch, error_post_pitch, error_pre_timing, error_post_timing, a=1, b=1):\n",
    "    diff_timing = error_post_timing - error_pre_timing\n",
    "    diff_pitch  = error_post_pitch  - error_pre_pitch\n",
    "    \n",
    "    \n",
    "    MEAN_UTILITY = 0.75\n",
    "    \n",
    "    return - (diff_timing*a + diff_pitch*b) - MEAN_UTILITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_diff_for_single_gp(gauss_model, recorded_points):\n",
    "    #calculate the policy diff for a single gp, given the recorded points and the expert decision\n",
    "    policy_diff = []\n",
    "    practice_mode_map = {'IMP_PITCH': PracticeMode.IMP_PITCH, 'IMP_TIMING': PracticeMode.IMP_TIMING}\n",
    "    #for all recorded data points\n",
    "    for i, point in recorded_points.iterrows():\n",
    "\n",
    "        #prepare the data in the right format for adding to the gp\n",
    "\n",
    "        point_data = point.drop(\"utility\")\n",
    "        expert_opt_policy = point[\"utility\"]\n",
    "        note_range = NoteRangePerHand.MEDIUM\n",
    "        tp = TaskParameters(bpm=point[\"bpm\"], note_range=note_range)\n",
    "        given_practice_mode = point[\"practice_mode\"]\n",
    "        my_practice_mode = practice_mode_map[given_practice_mode]\n",
    "        complexity_level = 0\n",
    "\n",
    "        #add the data point to the gp\n",
    "    \n",
    "        gauss_model.add_data_point(complexity_level,tp, my_practice_mode, expert_opt_policy)\n",
    "        gauss_model.update_model()\n",
    "        \n",
    "        #calculate the policy diff for the current gp, for the current point\n",
    "        \n",
    "        c=0#what is c?\n",
    "        curr_diff = compare_to_best_policy(gauss_model.get_policy(c),expert_opt_policy)\n",
    "        policy_diff.append(curr_diff)\n",
    "        \n",
    "    return policy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_diff_for_all_gauss_models(gauss_models, recorded_points):\n",
    "    policy_diff = []\n",
    "    #for each gp, we calculate the policy diff for each added data point\n",
    "    for i, gauss_model in enumerate(gauss_models):\n",
    "        policy_diff.append(policy_diff_for_single_gp(gauss_model, recorded_points))\n",
    "    #we retrun an array of arrays- array contains the policy diff for a single gp, for each added data point\n",
    "    return policy_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_with_kernel(self, kernel):\n",
    "    #it seems possible to enter the kernel to the functionality...\n",
    "\n",
    "        ## only calculate new model if data changed\n",
    "        if self.data_X is None or self.data_X.shape == self.data_X_old_shape:\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.data_X_old_shape = self.data_X.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bayes_opt = GPyOpt.methods.BayesianOptimization(\n",
    "            f = None, domain = self.domain, X = self.data_X, Y = self.data_Y,\n",
    "            maximize=True,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 0\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        \n",
    "        self.bayes_opt.model.model.kern.variance.constrain_bounded(0.2,1,\n",
    "                                                                   warning=False)\n",
    "        self.bayes_opt.model.model.kern.lengthscale.constrain_bounded(1, 2,\n",
    "                                                                   warning=False)\n",
    "        \n",
    "        self.bayes_opt.model.max_iters = 1000\n",
    "        self.bayes_opt.update_model_with_kernel(kernel) \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilize_gp():\n",
    "        gp_models = []\n",
    "        variance = [0.2]\n",
    "        lengthscale = [1]\n",
    "        alpha_list = [0.1]\n",
    "        #RBF kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "                #for each kernel, we initialize a gp model with different hyperparameters\n",
    "                #initial a gp instance\n",
    "                gp = GaussianProcess()\n",
    "                kernel = GPy.kern.RBF(input_dim=gp.space.model_dimensionality, \n",
    "                                variance=v, \n",
    "                                lengthscale=l)\n",
    "                #we use the update_model_with_kernel function to create the new model with the new kernel\n",
    "                gp.update_model_with_kernel(kernel)\n",
    "                gp_models.append(gp)\n",
    "        #MATERN52 kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "                #for each kernel, we initialize a gp model with different hyperparameters\n",
    "                #initial a gp instance\n",
    "                gp = GaussianProcess()\n",
    "                kernel = GPy.kern.Matern52(input_dim=gp.space.model_dimensionality, \n",
    "                              variance=v, \n",
    "                              lengthscale=l)\n",
    "                #we use the update_model_with_kernel function to create the new model with the new kernel\n",
    "                gp.update_model_with_kernel(kernel)\n",
    "                gp_models.append(gp)\n",
    "        #Rational Quadratic kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "                for alpha in alpha_list:\n",
    "                    # initialize a gp instance\n",
    "                    gp = GaussianProcess()\n",
    "                    kernel = GPy.kern.RatQuad(input_dim=gp.space.model_dimensionality, \n",
    "                                            variance=v, \n",
    "                                            lengthscale=l, \n",
    "                                            power=alpha)\n",
    "                    #we use the update_model_with_kernel function to create the new model with the new kernel\n",
    "                    gp.update_model_with_kernel(kernel)\n",
    "                    gp_models.append(gp)\n",
    "\n",
    "\n",
    "        #linear kernel\n",
    "        for v in variance:\n",
    "            for l in lengthscale:\n",
    "        # initialize a gp instance\n",
    "                gp = GaussianProcess()\n",
    "                kernel = GPy.kern.Linear(input_dim=gp.space.model_dimensionality, \n",
    "                                        variances=np.ones(gp.space.model_dimensionality)*v, \n",
    "                                        ARD=True, # set to True for Automatic Relevance Determination\n",
    "                                        )\n",
    "                kernel.lengthscale = np.ones(gp.space.model_dimensionality)*l\n",
    "                #we use the update_model_with_kernel function to create the new model with the new kernel\n",
    "                gp.update_model_with_kernel(kernel)\n",
    "                gp_models.append(gp)\n",
    "\n",
    "\n",
    "\n",
    "        return gp_models\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_gp(gauss_models, policy_diff):\n",
    "    #we choose the gp with the lowest mean policy diff\n",
    "    best_model_index = np.argmin([np.mean(pd) for pd in policy_diff])\n",
    "    best_model = gauss_models[best_model_index]\n",
    "    return best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 25.18 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "#gets a utility collumn for expert data\n",
    "expert_data[\"utility\"] = expert_data.apply(lambda row: error_diff_to_utility_for_opt(row[\"error_before_right_pitch\"],\n",
    "                                                                             row[\"error_after_right_pitch\"],\n",
    "                                                                             row[\"error_before_right_timing\"],\n",
    "                                                                             row[\"error_after_right_timing\"]),\n",
    "                                            axis=1)\n",
    "\n",
    "#currently just right timing and right pitch\n",
    "recorded_points = expert_data[[\"error_before_right_timing\", \"error_before_right_pitch\",\"practice_mode\", \"bpm\",\"utility\"]]\n",
    "#initilizing the gp models with different hyperparameters\n",
    "gauss_models = initilize_gp()\n",
    "#calculating the policy diff for each gp, for each added data point\n",
    "policy_diff = policy_diff_for_all_gauss_models(gauss_models, recorded_points)\n",
    "#choose the optimal gp\n",
    "best_gp = optimal_gp(gauss_models, policy_diff)\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "print(\"Time elapsed: {:.2f} seconds\".format(time_elapsed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "# Define the objective function\n",
    "def objective_function(x):\n",
    "    if x.ndim > 1:\n",
    "        x = x.flatten()\n",
    "    # x is a list of hyperparameters\n",
    "    variance, lengthscale, alpha = x[0], x[1], x[2]\n",
    "    # Initialize a GP model with the given hyperparameters\n",
    "    gp = GaussianProcess()\n",
    "    \n",
    "    kernel = GPy.kern.RatQuad(input_dim=gp.space.model_dimensionality, \n",
    "                              variance=variance, \n",
    "                              lengthscale=lengthscale,\n",
    "                              power=alpha)\n",
    "    gp.update_model_with_kernel(kernel)\n",
    "    # Calculate the utility using the expert data and the GP model\n",
    "    recorded_points = expert_data[[\"error_before_right_timing\", \"error_before_right_pitch\",\"practice_mode\", \"bpm\",\"utility\"]]\n",
    "    policy_diff = policy_diff_for_single_gp(gp, recorded_points)\n",
    "    return -policy_diff[0]\n",
    "\n",
    "# Define the bounds of the hyperparameters\n",
    "bounds = [{'name': 'variance', 'type': 'continuous', 'domain': (0.01, 1)},\n",
    "          {'name': 'lengthscale', 'type': 'continuous', 'domain': (0.1, 10)},\n",
    "          {'name': 'alpha', 'type': 'continuous', 'domain': (0.1, 10)}]\n",
    "\n",
    "# Define the optimization space\n",
    "#space = GPyOpt.core.task.space.Design_space(bounds)\n",
    "\n",
    "# Define the Bayesian optimization object\n",
    "bo = BayesianOptimization(f=objective_function,\n",
    "                                         domain=bounds,\n",
    "                                         acquisition_type='EI',\n",
    "                                         acquisition_jitter=0.05,\n",
    "                                         num_cores=1)\n",
    "\n",
    "\n",
    "\n",
    "# Run the optimization\n",
    "bo.run_optimization(max_iter=10)\n",
    "\n",
    "\n",
    "# Get the best set of hyperparameters\n",
    "best_hyperparameters = bo.x_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bo.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84287197, 4.09310338, 4.9987208 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DEBUGGING THE ADD DATA POINT PARAMETERS(CURRENTLY- TP)\n",
    "2. UNDERSTAND THE OPTIMIZATION PROCESS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3d1baa44583d8ec46d9c51771f1212390b5783b843e583a1bb6c33531f0efe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
